{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urkgEWYXCvJF"
      },
      "source": [
        "# Diagnostyka raka skóry z wykorzystaniem analizy obrazów dermatologicznych - trening modeli hybrydowych"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF4KvvFTCyCU"
      },
      "source": [
        "Celem tego treningu jest przygotowanie i wytrenowanie modeli hybrydowych, czyli łączących sieć neuronową z jednym z klasycznych modeli uczenia maszynowego. Wykorzystamy tutaj wyczone modele DenseNet-121 z pliku `02_trening_densenet.ipynb`, które wykorzystamy jako ekstraktory cech (odetniemy warstwę klasyfikacyjną). Wszelki cechy wyprodukowane przez te ekstraktory będą następnie wprowadzane do jednego z dwóch modeli: maszyny wektorów nośnych i lasy losowego. Modele te będą podejmowały decyzję diagnostyczną."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Xb7iCXNC0LS"
      },
      "source": [
        "## Konfiguracja środowiska"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljrp_Q6YC2w7"
      },
      "source": [
        "Importujemy potrzebne biblioteki."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4R9qkHxCnoY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive, files\n",
        "import kagglehub\n",
        "import random\n",
        "import time\n",
        "import copy\n",
        "import json\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from sklearn.metrics import matthews_corrcoef, accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint, loguniform\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import multiprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mAfMhnWC8sr"
      },
      "source": [
        "Definiujemy zmienne globalne."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bb00bhT6DASj"
      },
      "outputs": [],
      "source": [
        "# parametry globalne\n",
        "SEED = 42\n",
        "BATCH_SIZE = 64                                                         # wielkość partii danych\n",
        "NUM_WORKERS = min(4, multiprocessing.cpu_count())                       # liczba wątków procesora\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "NUM_CLASSES = 8                                                         # liczba klas\n",
        "MODEL_NAME = 'DenseNet-121'                                             # nazwa modelu\n",
        "\n",
        "# parametry transformacji obrazów\n",
        "IMG_SIZE = 300                      # wymiar wejściowy obrazu\n",
        "NORM_MEAN = [0.485, 0.456, 0.406]   # wartości średniej do normalizacji\n",
        "NORM_STD = [0.229, 0.224, 0.225]    # wartości odchyleń do normalizacji\n",
        "\n",
        "# parametry czyszczenia danych\n",
        "VIGNETTE_THRESHOLD = 20      # próg czerni\n",
        "EXTRA_CROP = 0.05            # margines dodatkowego przycięcia (5%)\n",
        "MIN_FILL_RATIO = 0.95        # bezpiecznik dla zdjęć pełnokadrowych\n",
        "\n",
        "# podział danych\n",
        "CV_FOLDS = 5                 # liczba foldów walidacyjnych"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWAAo51sDCL2"
      },
      "source": [
        "Aby móc uzyskać dostęp do GPU w notatniku należy wybrać:\n",
        "\n",
        "$\\textbf{Środowisko wykonawcze} ⟶ \\textbf{Zmień typ środowiska wykonwaczego} ⟶ \\text{Wybieramy jedno z dostępnych GPU} ⟶ \\textbf{Zapisz}$\n",
        "\n",
        "Po takiej sekwencji operacji należy przepuścić kod notatnika od samego początku, gdyż zostanie przydzielona nowa sesja, a poprzednia zostanie usunięta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFQS-LMUDEw8"
      },
      "source": [
        "Ustawiamy ziarno losości dla powtarzalności wyników."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTL2heW7DGcu"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed=42):\n",
        "    \"\"\"Ustawia ziarno losowości dla reprodukowalności wyników.\"\"\"\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2A6CGzcDIWu"
      },
      "outputs": [],
      "source": [
        "set_seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rozRSsqPDKkL"
      },
      "source": [
        "Dodatkowo konfigurujemy wygląd wykresów w całym notatniku."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_lw1YEADMUJ"
      },
      "outputs": [],
      "source": [
        "# bazowy styl seaborn z siatką\n",
        "sns.set_theme(style=\"whitegrid\", context=\"notebook\", font_scale=1.1)\n",
        "\n",
        "# ustawienia matplotlib\n",
        "plt.rcParams.update({\n",
        "    'figure.figsize': (10, 6),       # domyślny rozmiar wykresu\n",
        "    'figure.dpi': 120,               # wyraźny wygląd wykresów w Colabie\n",
        "    'savefig.dpi': 300,              # wysoka rozdzielczość zapisywanych wykresów\n",
        "    'savefig.bbox': 'tight',         # automatycznie przycinanie białych marginesów przy zapisie\n",
        "    'font.family': 'sans-serif',     # wykorzystanie czcionki bezszerfyowej\n",
        "    'font.sans-serif': ['DejaVu Sans', 'Arial'],\n",
        "    'axes.spines.top': False,        # usuwanie górnej ramki\n",
        "    'axes.spines.right': False,      # usuwanie prawej ramki\n",
        "})\n",
        "\n",
        "# wyostrzone grafiki w Colabie\n",
        "%config InlineBackend.figure_format = 'retina'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmgVEIETDOkw"
      },
      "source": [
        "Konfigurujemy wszelki potrzebne ścieżki."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XV90Vir1DQLB",
        "outputId": "f306cbc2-e25d-46ef-e457-c1c80ff8c312"
      },
      "outputs": [],
      "source": [
        "# montowanie Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# podajemy nazwę głównego folderu projektu\n",
        "PROJECT_FOLDER_NAME = 'Implementacja'\n",
        "BASE_DIR = os.path.join('/content/drive/MyDrive/Diagnostyka raka skóry z wykorzystaniem analizy obrazów dermatologicznych', PROJECT_FOLDER_NAME)\n",
        "\n",
        "# podajemy ścieżkę w Colabie do zapisania pobieranych danych\n",
        "DATA_ROOT_DIR = '/content/ISIC2019'\n",
        "IMG_DIR = os.path.join(DATA_ROOT_DIR, 'images')\n",
        "PROCESSED_DIR = os.path.join(DATA_ROOT_DIR, 'images_processed')\n",
        "\n",
        "# definijemy podfoldery\n",
        "MODELS_DIR = os.path.join(BASE_DIR, 'Modele')\n",
        "RESULTS_DIR = os.path.join(BASE_DIR, 'Wyniki')\n",
        "DATA_DIR = os.path.join(BASE_DIR, 'Dane')\n",
        "\n",
        "# tworzymy foldery na Google Drive (jeśli nie istnieją)\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Katalog roboczy projektu: {BASE_DIR}\")\n",
        "print(f\"Dane będą zapisywane w: {DATA_ROOT_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJ94J8uBDSsE"
      },
      "source": [
        "### Konfiguracja Kaggle API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SLfrykfDUp-"
      },
      "source": [
        "Kaggle API jest nam potrzebne do pobrania danych bezpośrednio do notatnika. Folder ZIP jest bardzo obszernym plikiem i ręczne wgrywanie go na Google Drive może zająć bardzo dużo czasu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4wTZIX7DWs7"
      },
      "source": [
        "Kofigurujemy ścieżkę dla Kaggle API. Klucz będzie zapisywany bezpośrednio w folderze projektu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWJa8YmMDYYI"
      },
      "outputs": [],
      "source": [
        "kaggle_key_drive_path = os.path.join(BASE_DIR, 'kaggle.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hePDcVB_DaOy"
      },
      "source": [
        "Tworzymy w Colabie folder na plik z Kaggle API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXZLBIF_DbrZ"
      },
      "outputs": [],
      "source": [
        "kaggle_sys_dir = '/root/.kaggle'\n",
        "os.makedirs(kaggle_sys_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxr-J0NaDd_q"
      },
      "source": [
        "Wprowadzamy Kaggle API. Klucz ten należy utworzyć indywidualnie dla każdego użytkownika notatników z implementacją pracy inżynierskie. Aby go zdobyć należy:\n",
        "1. Zalogować się na swój profil na stronie Kaggle.\n",
        "2. Wejście w ustawienia swojego profilu (kilkamy na swoje zdjęcie profilowe i wybieramy ,,Settings'').\n",
        "3. W sekcji ,,API'' klikamy ,,Generate New Token'', następnie wprowadzamy nazwę tokenu i klikamy ,,Generate''.\n",
        "4. Kopiujemy kod z okienka ,,API TOKEN''.\n",
        "5. W dowolnym edytorze tekstu (np. Notatniku) wprowadzamy tekst o następującej strykturze\n",
        "$$\\{\\text{\"username\":\"nazwa_uzytkownika_kaggle\",\"key\":\"skopiowane_kaggle_api\"}\\}$$\n",
        "i zapisujemy plik jako ,,kaggle.json''.\n",
        "W poniższej funkcji zostaniemy poproszeni o wgranie utworzonego pliku.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jvmV273DhGA"
      },
      "outputs": [],
      "source": [
        "# sprawdzamy czy klucz jest już na Drive\n",
        "if not os.path.exists(kaggle_key_drive_path):\n",
        "    print(f\"UWAGA: Nie znaleziono pliku kaggle.json w lokalizacji: {kaggle_key_drive_path}\")\n",
        "    print(\"Proszę przesłać plik kaggle.json teraz (zostanie zapisany na Drive):\")\n",
        "\n",
        "    # przesyłamy plik kaggle.json\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for filename in uploaded.keys():\n",
        "        if filename == 'kaggle.json':\n",
        "            # zapisujemy trwale na Google Drive\n",
        "            with open(kaggle_key_drive_path, 'wb') as f:\n",
        "                f.write(uploaded[filename])\n",
        "            print(f\"Zapisano kaggle.json w: {kaggle_key_drive_path}\")\n",
        "        else:\n",
        "            print(f\"Pominięto plik: {filename} (oczekiwano kaggle.json)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSClcakSDi_5"
      },
      "source": [
        "## Pobranie danych"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCK5RQWODk1j"
      },
      "source": [
        "Pobieramy, rozpakowujemy i porządkujemy zbiór ISIC2019. Nie pobieramy obrazów na dysk Google Drive, lecz do pamięci Google Colab. Pozwoli to na sprawniejsze wczytywanie plików w notatniku."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2A0opmrDm3g",
        "outputId": "545d0a72-2442-44fe-e697-0dd9e776f997"
      },
      "outputs": [],
      "source": [
        "if os.path.exists(kaggle_key_drive_path):\n",
        "    # instalacja klucza w systemie\n",
        "    shutil.copy(kaggle_key_drive_path, os.path.join(kaggle_sys_dir, 'kaggle.json'))\n",
        "    os.chmod(os.path.join(kaggle_sys_dir, 'kaggle.json'), 600)\n",
        "    print(\"Klucz Kaggle API skonfigurowany.\")\n",
        "\n",
        "    # POBIERANIE I PORZĄDKOWANIE DANYCH\n",
        "\n",
        "    # sprawdzamy, czy folder ze zdjęciami już istnieje i jest pełny\n",
        "    # (np. czy nie uruchamiamy komórki drugi raz w tej samej sesji)\n",
        "    if not os.path.exists(IMG_DIR):\n",
        "        print(\"\\nPobieranie danych z Kaggle...\")\n",
        "        # pobieramy do folderu tymczasowego\n",
        "        path = kagglehub.dataset_download(\"andrewmvd/isic-2019\")\n",
        "        print(f\"Pobrano dane do folderu tymczasowego: {path}\")\n",
        "\n",
        "        # tworzymy docelowe foldery na obrazy\n",
        "        os.makedirs(IMG_DIR, exist_ok=True)\n",
        "        os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
        "\n",
        "        # przenosimy metadane w folderu z danymi w Colabie\n",
        "        for csv_file in glob.glob(os.path.join(path, \"*.csv\")):\n",
        "            shutil.copy(csv_file, DATA_ROOT_DIR)\n",
        "            print(f\"Przeniesiono: {os.path.basename(csv_file)}\")\n",
        "\n",
        "        # szukamy rekursywnie zdjęć we wszystkich podfolderach pobranych danych\n",
        "        jpg_files = glob.glob(os.path.join(path, \"**\", \"*.jpg\"), recursive=True)\n",
        "\n",
        "        print(f\"Znaleziono {len(jpg_files)} zdjęć.\")\n",
        "\n",
        "        for file_path in tqdm(jpg_files, desc=\"Kopiowanie zdjęć\", unit=\"plik\"):\n",
        "            # przenosimy plik do wspólnego folderu\n",
        "            shutil.copy(file_path, os.path.join(IMG_DIR, os.path.basename(file_path)))\n",
        "        print(\"Przeniesiono zdjęcia do folderu z danymi.\")\n",
        "\n",
        "        # weryfikujemy liczbę plików\n",
        "        num_images = len(os.listdir(IMG_DIR))\n",
        "        print(f\"\\nSUKCES: Dane gotowe w {DATA_ROOT_DIR}\")\n",
        "        print(f\"Liczba zdjęć w {IMG_DIR}: {num_images}\")\n",
        "\n",
        "    else:\n",
        "        print(\"Dane są już pobrane i uporządkowane.\")\n",
        "        print(f\"Lokalizacja zdjęć: {IMG_DIR}\")\n",
        "\n",
        "else:\n",
        "    print(\"BŁĄD: Brak pliku kaggle.json. Nie można pobrać danych.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSEAhP82Dow6"
      },
      "source": [
        "## Przygotowanie danych do treningu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVuaLB-tDrWH"
      },
      "source": [
        "Wczytujemy metadane."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "rFyK3rBRDs8q",
        "outputId": "84499cbd-3e22-4b7b-869e-8c3e715c8f8b"
      },
      "outputs": [],
      "source": [
        "metadata_processed_path = os.path.join(DATA_DIR, 'ISIC_metadata_processed.csv')\n",
        "df = pd.read_csv(metadata_processed_path)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xveAjyQPDumR"
      },
      "source": [
        "Wczytujemy i przycinamy zdjęcia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLV_ig6VDwSO"
      },
      "outputs": [],
      "source": [
        "def crop_vignette(image_path, output_path, threshold=20, extra_crop_percent=0.05, min_fill_ratio=0.95):\n",
        "    \"\"\"\n",
        "    Funkcja usuwająca czarne ramki (winiety) z obrazu z dodatkowym marginesem bezpieczeństwa\n",
        "    oraz mechanizmem chroniącym zdjęcia pełnokadrowe.\n",
        "\n",
        "    Parametry:\n",
        "    - image_path: ścieżka do pliku wejściowego.\n",
        "    - output_path: ścieżka zapisu pliku wynikowego.\n",
        "    - threshold: próg jasności (0-255). Piksele ciemniejsze niż ta wartość są traktowane jako tło.\n",
        "    - extra_crop_percent: ułamek (np. 0.05 = 5%), o jaki dodatkowo zmniejszamy ramkę z każdej strony,\n",
        "      aby usunąć postrzępione krawędzie lub pozostałości winiety w rogach.\n",
        "    - min_fill_ratio: współczynnik wypełnienia (zakres 0.0 - 1.0). Określa próg decyzyjny,\n",
        "      czy zdjęcie w ogóle wymaga przycinania. Jeśli wykryty obszar treści zajmuje większą część\n",
        "      zdjęcia niż ta wartość (np. > 95%), algorytm uznaje, że winieta nie występuje (lub jest pomijalna)\n",
        "      i rezygnuje z przycinania, aby nie uszkodzić zmian skórnych dotykających krawędzi.\n",
        "    \"\"\"\n",
        "\n",
        "    # wczytujemy obraz z dysku\n",
        "    img = cv2.imread(image_path)\n",
        "\n",
        "    # jeśli plik jest uszkodzony lub nie istnieje, przerywamy\n",
        "    if img is None:\n",
        "        return False, None\n",
        "\n",
        "    # przekształcamy obraz do skali szarości i wyznaczmy obszar zdjęcia\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    h_img, w_img = gray.shape\n",
        "    total_area = h_img * w_img\n",
        "\n",
        "    # tworzymy maskę binarną:\n",
        "    # - piksele > threshold (treść) dostają wartość 255 (biały)\n",
        "    # - piksele <= threshold (tło/winieta) dostają wartość 0 (czarny)\n",
        "    _, mask = cv2.threshold(gray, threshold, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # znajdujemy położenie treści\n",
        "    # cv2.findNonZero zwraca listę współrzędnych wszystkich białych pikseli na masce\n",
        "    coords = cv2.findNonZero(mask)\n",
        "\n",
        "    # jeśli nie znaleziono żadnych jasnych punktów (zdjęcie jest całe czarne), kończymy\n",
        "    if coords is None:\n",
        "        return False, None\n",
        "\n",
        "    # znajdujemy najmniejszy prostokąt (x, y, szerokość, wysokość), który obejmuje wszystkie jasne punkty\n",
        "    x, y, w, h = cv2.boundingRect(coords)\n",
        "\n",
        "    # obliczamy obszar czystego obrazu oraz współczynnik wypełnienia\n",
        "    rect_area = w * h\n",
        "    fill_ratio = rect_area / total_area\n",
        "\n",
        "    # jeśli treść zajmuje prawie cały obraz (> 95%), to znaczy, że nie ma winiety,\n",
        "    # albo są tylko mikro-paski, których nie warto ruszać, by nie uciąć zmiany\n",
        "    if fill_ratio > min_fill_ratio:\n",
        "        return False, None\n",
        "\n",
        "    # ETAP PRZYCINANIA\n",
        "\n",
        "    # obliczamy ile pikseli uciąć dodatkowo z każdej strony (5% szerokości/wysokości znalezionej ramki)\n",
        "    margin_w = int(w * extra_crop_percent)\n",
        "    margin_h = int(h * extra_crop_percent)\n",
        "\n",
        "    # wyznaczamy nowe współrzędne ramki, zawężając ją do środka:\n",
        "    # przesuwamy początek X w prawo i Y w dół\n",
        "    new_x = x + margin_w\n",
        "    new_y = y + margin_h\n",
        "\n",
        "    # zmniejszamy szerokość i wysokość o marginesy z obu stron (lewo+prawo, góra+dół)\n",
        "    new_w = w - (2 * margin_w)\n",
        "    new_h = h - (2 * margin_h)\n",
        "\n",
        "    # jeśli zdjęcie było bardzo małe lub margines był za duży i \"zjadł\" cały obraz (wymiar <= 0),\n",
        "    # to cofamy się do wersji podstawowej (bez cięcia).\n",
        "    if new_w <= 0 or new_h <= 0:\n",
        "        new_x, new_y, new_w, new_h = x, y, w, h\n",
        "\n",
        "    # sprawdzamy czy przycięcie jest konieczne\n",
        "    # pobieramy oryginalne wymiary obrazu\n",
        "    h_img, w_img = gray.shape\n",
        "\n",
        "    # czy nowa, wyliczona ramka jest mniejsza niż oryginalny obraz?\n",
        "    # jeśli tak, wykonujemy fizyczne cięcie obrazu\n",
        "    if (new_w < w_img) or (new_h < h_img):\n",
        "        # wycinanie fragmentu tablicy\n",
        "        cropped_img = img[new_y:new_y+new_h, new_x:new_x+new_w]\n",
        "\n",
        "        # zapisujemy wynik na dysk\n",
        "        cv2.imwrite(output_path, cropped_img)\n",
        "\n",
        "        # zwracamy sukces oraz informację, ile pikseli ucięto z każdej strony (góra, dół, lewo, prawo)\n",
        "        return True, (new_y, h_img-(new_y+new_h), new_x, w_img-(new_x+new_w))\n",
        "\n",
        "    # jeśli nie trzeba było ciąć (ramka pokrywa się z całym obrazem), zwracamy False\n",
        "    return False, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2GOFbDKDyHq",
        "outputId": "5d592dd9-68cf-473a-c6cd-40bcea2e30e1"
      },
      "outputs": [],
      "source": [
        "# filtrujemy pliki, biorąc tylko te z rozszerzeniem .jpg lub .png\n",
        "image_files = [f for f in os.listdir(IMG_DIR) if f.lower().endswith(('.jpg', '.png'))]\n",
        "\n",
        "cropped_count = 0\n",
        "copied_count = 0\n",
        "\n",
        "print(f\"Start: {len(image_files)} zdjęć. Dodatkowe cięcie: {EXTRA_CROP*100}%\")\n",
        "\n",
        "# pętla po wszystkich zdjęciach z użyciem paska postępu\n",
        "for f in tqdm(image_files, desc=\"Przetwarzanie\"):\n",
        "\n",
        "    # tworzenie pełnych ścieżek\n",
        "    src_path = os.path.join(IMG_DIR, f)\n",
        "    dst_path = os.path.join(PROCESSED_DIR, f)\n",
        "\n",
        "    # wywołujemy cięcie\n",
        "    is_cropped, _ = crop_vignette(src_path, dst_path, threshold=VIGNETTE_THRESHOLD, extra_crop_percent=EXTRA_CROP, min_fill_ratio=MIN_FILL_RATIO)\n",
        "\n",
        "    if is_cropped:\n",
        "        # jeśli funkcja wykonała cięcie i zapisała plik -> zwiększ licznik\n",
        "        cropped_count += 1\n",
        "    else:\n",
        "        # jeśli funkcja nie przycięła zdjęcia (zwróciła False) -> kopiujemy oryginał bez zmian\n",
        "        shutil.copy(src_path, dst_path)\n",
        "        copied_count += 1\n",
        "\n",
        "print(\"\\nZakończono przycinanie.\")\n",
        "print(f\"Przycięto: {cropped_count}\")\n",
        "print(f\"Skopiowano (bez zmian): {copied_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vS234vuXD0Md"
      },
      "source": [
        "## Budowa pętli treningowej"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ftrq8LPqD15n"
      },
      "source": [
        "Przejdziemy do wytrenowania modeli hybrydowych. Zdecydowaliśmy na modele DenseNet-121 + SVM oraz DenseNet-121 + Las losowy. Będziemy tutaj traktować model sieci splotowej jak ekstraktor cech, które zostaną następnie wprowadzony do klasyfikatorów."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVrk7vWtD3yt"
      },
      "source": [
        "Przywołujemy klasę `ISICDataset`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xuc5X9HHD5Y3"
      },
      "outputs": [],
      "source": [
        "class ISICDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Niestandardowy Dataset PyTorch do wczytywania obrazów dermatologicznych ISIC.\n",
        "\n",
        "    Klasa wczytuje obrazy na podstawie ścieżek z DataFrame, konwertuje je do RGB\n",
        "    i zwraca w formie gotowej do przetworzenia przez model.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataframe, root_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Inicjalizuje dataset.\n",
        "\n",
        "        Args:\n",
        "            dataframe (pd.DataFrame): Ramka danych zawierająca co najmniej kolumny:\n",
        "                                      - 'nazwa_pliku': nazwa pliku z rozszerzeniem (np. 'IMG_1.jpg')\n",
        "                                      - 'target': numeryczna etykieta klasy (int).\n",
        "            root_dir (str): Ścieżka do katalogu głównego, w którym znajdują się obrazy.\n",
        "            transform (callable, optional): Opcjonalne transformacje (np. augmentacja, normalizacja)\n",
        "                                            aplikowane na obrazie. Domyślnie None.\n",
        "        \"\"\"\n",
        "        self.df = dataframe\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Zwraca całkowitą liczbę próbek w zbiorze.\"\"\"\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Pobiera pojedynczą próbkę danych o podanym indeksie.\n",
        "\n",
        "        Args:\n",
        "            idx (int/tensor): Indeks próbki do pobrania.\n",
        "\n",
        "        Returns:\n",
        "            tuple: Krotka (image, label), gdzie:\n",
        "                   - image (PIL.Image lub Tensor): Obraz po transformacjach.\n",
        "                   - label (int): Numeryczna etykieta klasy.\n",
        "        \"\"\"\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        # pobranie nazwy pliku\n",
        "        img_name = self.df.iloc[idx]['nazwa_pliku']\n",
        "        img_path = os.path.join(self.root_dir, img_name)\n",
        "\n",
        "        # wczytanie obrazu i konwersja na RGB (dla bezpieczeństwa)\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        # pobranie etykiety numerycznej (target)\n",
        "        label = self.df.iloc[idx]['target']\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vo9XyZimD7s4"
      },
      "source": [
        "Nie bedziemy korzystać już z augumentacji danych, ponieważ modele DenseNet-121 są już wytrenowane. Wystarczą transformacje zbioru walidacyjnego stosowane do zbioru treningowego i walidacyjnego."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubzRnPYzD9PW"
      },
      "outputs": [],
      "source": [
        "working_size = int(IMG_SIZE * 1.25)\n",
        "\n",
        "feature_extraction_transforms =  transforms.Compose([\n",
        "    # zmiana wymiarów\n",
        "    transforms.Resize(working_size),\n",
        "    # wycinamy środek obrazu w docelowych wymiarach\n",
        "    transforms.CenterCrop(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(NORM_MEAN, NORM_STD)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmPm30a2D_BX"
      },
      "source": [
        "Tworzymy funkcję, które będzie wczytywać model i jego wytrenowane wagi, a następnie zmodyfikuje warstwę klasyfikacyjną, aby model stał się ekstraktorem cech."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLxb32avEAk6"
      },
      "outputs": [],
      "source": [
        "def get_densenet_extractor(weights_path, device):\n",
        "    \"\"\"\n",
        "    Wczytuje wytrenowany model DenseNet-121 i konwertuje go na ekstraktor cech.\n",
        "\n",
        "    Funkcja najpierw odtwarza architekturę użytą podczas treningu (aby poprawnie\n",
        "    wczytać wagi), a następnie zamienia warstwę klasyfikacyjną na funkcję tożsamościową,\n",
        "    dzięki czemu model zwraca wektory cech zamiast predykcji klas.\n",
        "\n",
        "    Args:\n",
        "        weights_path (str): Ścieżka do pliku .pth z zapisanymi wagami modelu.\n",
        "        device (torch.device): Urządzenie (CPU/GPU), na które ma trafić model.\n",
        "\n",
        "    Returns:\n",
        "        torch.nn.Module: Model w trybie ewaluacji, zwracający cechy (embeddings).\n",
        "                         Zwraca None, jeśli wczytanie wag się nie powiedzie.\n",
        "    \"\"\"\n",
        "    # inicjalizujemy pusty model\n",
        "    model = models.densenet121(weights=None)\n",
        "    in_features = model.classifier.in_features\n",
        "\n",
        "    # odtwarzamy warstwę klasyfikacyjną z notatnika z treningu\n",
        "    model.classifier = nn.Sequential(\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(in_features, NUM_CLASSES)\n",
        "    )\n",
        "\n",
        "    # wczytujemy wagi\n",
        "    try:\n",
        "        state_dict = torch.load(weights_path, map_location=device)\n",
        "        model.load_state_dict(state_dict)\n",
        "        print(f\"  -> Wczytano wagi modelu: {os.path.basename(weights_path)}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"  [BŁĄD] Nie znaleziono pliku wag: {weights_path}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"  [BŁĄD] Problem z wczytaniem wag: {e}\")\n",
        "        return None\n",
        "\n",
        "    # modyfikujemy warstwę klasyfikacyjną, aby zwracała ostatni wynik warstw splotowych\n",
        "    model.classifier = nn.Identity()\n",
        "\n",
        "    # przenosimy na GPU (jeśli dostępne)\n",
        "    model.to(device)\n",
        "    # włączamy tryb ewaluacji\n",
        "    model.eval()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eH-A6OgsESXh"
      },
      "source": [
        "Defniujemy wartości hiperparametrów do przeszukiwania podczas trenowania klasyfikatorów. Ze względu na nierównomierne rozłożenie klas wprowadzamy własnej wagi do przeszukiwania hiperparametrów."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIyf27BOGXA7",
        "outputId": "9dff4481-1a85-46b1-fbf0-1954a6f92150"
      },
      "outputs": [],
      "source": [
        "# zliczamy elementy klas\n",
        "class_counts = df['target'].value_counts().sort_index()\n",
        "total_samples = len(df)\n",
        "\n",
        "# wyznaczamy wagi i normalizujemy\n",
        "weights_sqrt = 1. / np.sqrt(class_counts.values)\n",
        "weights_sqrt = weights_sqrt / np.mean(weights_sqrt)\n",
        "\n",
        "# tworzymy słownik {klasa: waga}\n",
        "custom_weights_dict = dict(zip(class_counts.index, weights_sqrt))\n",
        "\n",
        "# sprawdzamy słownik\n",
        "for cls, w in custom_weights_dict.items():\n",
        "    print(f\"  Klasa {cls}: {w:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-k6YjYUG3PB"
      },
      "source": [
        "Definiujemy rozkład wartości hiperparametró do przeszukania dla SVM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5w8gXDyMEdJu"
      },
      "outputs": [],
      "source": [
        "param_dist_svm = {\n",
        "    'C': loguniform(1e-2, 1e2),\n",
        "    'kernel': ['rbf', 'linear'],\n",
        "    'gamma': ['scale', 'auto'],\n",
        "    'class_weight': ['balanced', None, custom_weights_dict]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6K9m52TWG_MT"
      },
      "source": [
        "Analogicznie definiujemy dla lasu losowego."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cN0sMFz7HCwn"
      },
      "outputs": [],
      "source": [
        "param_dist_rf = {\n",
        "    'n_estimators': randint(100, 500),\n",
        "    'max_depth': [None, 10, 20, 30, 50],\n",
        "    'min_samples_split': randint(2, 20),\n",
        "    'min_samples_leaf': randint(1, 10),\n",
        "    'class_weight': ['balanced', 'balanced_subsample', None, custom_weights_dict]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UL_g2nzEJv5I"
      },
      "source": [
        "Definiujemy funkcję, która będzie wczytywać model dla wprowadzonego numeru podzbioru."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wU0o8bHzEqVF"
      },
      "outputs": [],
      "source": [
        "def load_feature_extractor(fold_idx):\n",
        "    \"\"\"\n",
        "    Wczytuje model DenseNet (jako ekstraktor cech) dla wskazanego foldu walidacji krzyżowej.\n",
        "\n",
        "    Funkcja konstruuje ścieżkę do pliku z wagami na podstawie indeksu foldu\n",
        "    (np. 'densenet121_fold_0.pth'), a następnie inicjalizuje model w trybie ewaluacji.\n",
        "\n",
        "    Args:\n",
        "        fold_idx (int): Numer foldu (np. 0, 1, 2...), dla którego ma zostać wczytany model.\n",
        "\n",
        "    Returns:\n",
        "        torch.nn.Module: Model gotowy do ekstrakcji cech.\n",
        "                         Zwraca None, jeśli plik z wagami nie istnieje (z wypisaniem ostrzeżenia).\n",
        "    \"\"\"\n",
        "    # tworzymy ścieżkę pliku\n",
        "    weights_filename = f'{MODEL_NAME}_fold{fold_idx}.pth'\n",
        "    model_path = os.path.join(MODELS_DIR, weights_filename)\n",
        "\n",
        "    # przygotowujemy model\n",
        "    model = get_densenet_extractor(model_path, DEVICE)\n",
        "\n",
        "    if model is None:\n",
        "        print(f\"[WARNING] Pominięto fold {fold_idx} z powodu braku pliku wag.\")\n",
        "        return None\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTz3ScvSJ6do"
      },
      "source": [
        "Analogicznie definiujemy funkcję, która utworzy zbiór treningowy i walidacyjny oraz loadery."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqfC54uBH_Ql"
      },
      "outputs": [],
      "source": [
        "def get_fold_data(df, fold_idx):\n",
        "    \"\"\"\n",
        "    Przygotowuje DataLoadery do etapu ekstrakcji cech (trening hybrydowy).\n",
        "\n",
        "    Funkcja dzieli dane na zbiór treningowy (n-1 foldów) i walidacyjny (1 fold)\n",
        "    w oparciu o indeks foldu. Stosuje transformacje deterministyczne (bez losowej augmentacji),\n",
        "    co jest wymagane do wygenerowania stabilnych wektorów cech dla klasyfikatorów.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): Główna ramka danych z metadanymi (wymaga kolumn 'typ_puli' i 'nr_podzbioru').\n",
        "        fold_idx (int): Indeks foldu, który ma służyć jako zbiór walidacyjny (np. 0, 1... 4).\n",
        "\n",
        "    Returns:\n",
        "        tuple: Krotka (train_loader, val_loader) skonfigurowana do sekwencyjnego przetwarzania danych\n",
        "               (shuffle=False dla obu loaderów).\n",
        "    \"\"\"\n",
        "    # filtrujemy zbiór treningowy i walidacyjny\n",
        "    train_df = df[(df['typ_puli'] == 'trening') & (df['nr_podzbioru'] != fold_idx)].reset_index(drop=True)\n",
        "    val_df = df[(df['typ_puli'] == 'trening') & (df['nr_podzbioru'] == fold_idx)].reset_index(drop=True)\n",
        "\n",
        "    # konstruujemy datasety\n",
        "    train_ds = ISICDataset(train_df,IMG_DIR, transform=feature_extraction_transforms)\n",
        "    val_ds = ISICDataset(val_df, IMG_DIR, transform=feature_extraction_transforms)\n",
        "\n",
        "    # konstruujemy loadery\n",
        "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
        "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
        "\n",
        "    return train_loader, val_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7fbKl3aKA3G"
      },
      "source": [
        "Konstruujemy teraz funkcje, których zadaniem będzie ekstrakcja cech za pomocą wczytanego modelu, a następnie ustandaryzowanie ich (w szczególności dla modelu SVM). Dodatkowo mierzy czas ekstrakcji cech."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGIi6QDd1S88"
      },
      "outputs": [],
      "source": [
        "def extract_features(model, loader, device):\n",
        "    \"\"\"\n",
        "    Generuje wektory cech dla całego zbioru danych przy użyciu modelu.\n",
        "\n",
        "    Funkcja iteruje przez DataLoader, przetwarza obrazy w trybie ewaluacji (bez liczenia gradientów)\n",
        "    i zwraca wynikowe cechy w formacie NumPy, gotowym dla klasycznych modeli ML.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): Model sieci neuronowej pełniący rolę ekstraktora cech.\n",
        "        loader (DataLoader): DataLoader dostarczający dane (zalecane shuffle=False).\n",
        "        device (torch.device): Urządzenie obliczeniowe (CPU lub CUDA).\n",
        "\n",
        "    Returns:\n",
        "        tuple: Krotka (X, y), gdzie:\n",
        "               - X (np.ndarray): Macierz cech o wymiarach [liczba_próbek, liczba_cech].\n",
        "               - y (np.ndarray): Wektor etykiet o wymiarach [liczba_próbek].\n",
        "    \"\"\"\n",
        "    model.eval()  # włączamy tryb ewaluacji\n",
        "\n",
        "    all_features = []\n",
        "    all_labels = []\n",
        "\n",
        "    # wyłączamy obliczanie gradientów dla oszczędności pamięci i przyspieszenia\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(loader, desc=\"Ekstrakcja cech\", leave=False):\n",
        "            inputs = inputs.to(device)\n",
        "\n",
        "            # Przepuszczamy obraz przez sieć\n",
        "            features = model(inputs)\n",
        "\n",
        "            # przenosimy wyniki z GPU na CPU i zamieniamy na numpy array\n",
        "            all_features.append(features.cpu().numpy())\n",
        "            all_labels.append(labels.numpy())\n",
        "\n",
        "    # łączymy wyniki ze wszystkich batchy w jedną dużą tablicę\n",
        "    # X będzie miało wymiar [liczba_zdjęć, liczba_cech]\n",
        "    X = np.concatenate(all_features, axis=0)\n",
        "    y = np.concatenate(all_labels, axis=0)\n",
        "\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnKC-du2IC-z"
      },
      "outputs": [],
      "source": [
        "def process_features(model, train_loader, val_loader, fold_idx):\n",
        "    \"\"\"\n",
        "    Realizuje proces ekstrakcji cech, ich standaryzacji oraz zapisu modelu skalującego.\n",
        "\n",
        "    Funkcja wykorzystuje podany model do transformacji obrazów na wektory cech.\n",
        "    Następnie cechy są skalowane przy użyciu StandardScaler. Skaler jest dopasowywany (fit)\n",
        "    wyłącznie do danych treningowych, a następnie aplikowany do walidacyjnych, co zapobiega\n",
        "    wyciekowi informacji (data leakage). Dopasowany skaler jest zapisywany na dysku.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): Model ekstraktora cech (powinien być w trybie eval).\n",
        "        train_loader (DataLoader): Loader dostarczający dane treningowe.\n",
        "        val_loader (DataLoader): Loader dostarczający dane walidacyjne.\n",
        "        fold_idx (int): Indeks bieżącego foldu (wykorzystywany do unikalnego nazwania\n",
        "                        zapisywanego pliku ze skalerem).\n",
        "\n",
        "    Returns:\n",
        "        tuple: Krotka (X_train, y_train, X_val, y_val, extraction_time), gdzie:\n",
        "            - X_train, X_val (np.ndarray): Ustandaryzowane macierze cech.\n",
        "            - y_train, y_val (np.ndarray): Wektory etykiet odpowiadające cechom.\n",
        "            - extraction_time (float): Czas trwania samej ekstrakcji cech (w sekundach).\n",
        "\n",
        "    Side Effects:\n",
        "        Zapisuje plik 'scaler_fold_{fold_idx}.joblib' w katalogu wskazanym przez globalną\n",
        "        zmienną MODELS_DIR.\n",
        "    \"\"\"\n",
        "    print(\"Rozpoczynam ekstrakcję cech.\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # ekstrakcja cech na zbiorze treningowym i walidacyjnym\n",
        "    X_train, y_train = extract_features(model, train_loader, DEVICE)\n",
        "    X_val, y_val = extract_features(model, val_loader, DEVICE)\n",
        "\n",
        "    extraction_time = time.time() - start_time\n",
        "    print(f\"Ekstrakcja zakończona w {extraction_time:.1f}s.\")\n",
        "\n",
        "    # standaryzacja cech\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_val = scaler.transform(X_val)\n",
        "    print(\"Dane ustandaryzowano.\")\n",
        "\n",
        "    # zapisujemy StandardScaler\n",
        "    scaler_path = os.path.join(MODELS_DIR, f'scaler_fold_{fold_idx}.joblib')\n",
        "    joblib.dump(scaler, scaler_path)\n",
        "    print(f\"Zapisano scaler do: {scaler_path}\")\n",
        "\n",
        "    return X_train, y_train, X_val, y_val, extraction_time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eUxtDDqLmxW"
      },
      "source": [
        "Zbudujemy teraz pętlę, które będzie przeprowadzać trening modeli na jednym foldzie. Do tego potrzebujemy funkcji do obliczania sepcyficzności (z `02_model_densenet.ipynb`) oraz funkcji do trenowania i dostrojenia klasyfikatora."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGQ2QITzLUDq"
      },
      "outputs": [],
      "source": [
        "def calculate_specificity(y_true, y_pred, num_classes):\n",
        "    \"\"\"\n",
        "    Oblicza średnią specyficzność dla klasyfikacji wieloklasowej.\n",
        "\n",
        "    Funkcja wykorzystuje strategię One-vs-Rest, obliczając specyficzność niezależnie\n",
        "    dla każdej klasy (binarna klasyfikacja: dana klasa vs reszta), a następnie zwraca\n",
        "    ich średnią arytmetyczną. Jest to kluczowa metryka w diagnostyce,\n",
        "    określająca zdolność modelu do poprawnego wykluczania danej choroby.\n",
        "\n",
        "    Args:\n",
        "        y_true (array-like): Wektor rzeczywistych etykiet.\n",
        "        y_pred (array-like): Wektor przewidzianych etykiet.\n",
        "        num_classes (int): Całkowita liczba klas w modelu.\n",
        "\n",
        "    Returns:\n",
        "        float: Uśredniona wartość specyficzności (zakres 0.0 - 1.0).\n",
        "    \"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=range(num_classes))\n",
        "    specificity_per_class = []\n",
        "\n",
        "    for i in range(num_classes):\n",
        "        # dla klasy 'i':\n",
        "        # TN = suma wszystkich próbek, które nie są 'i' i nie zostały przewidziane jako 'i'\n",
        "        # FP = próbki, które nie są 'i', ale zostały przewidziane jako 'i'\n",
        "\n",
        "        # wartości w macierzt pomyłek:\n",
        "        # cm[i, i] to TP\n",
        "        # cm[:, i] to kolumna predykcji (suma to TP + FP) -> FP = suma_kol - TP\n",
        "        # cm[i, :] to wiersz prawdy (suma to TP + FN)\n",
        "        # suma całkowita to total\n",
        "\n",
        "        tp = cm[i, i]\n",
        "        fp = cm[:, i].sum() - tp\n",
        "        fn = cm[i, :].sum() - tp\n",
        "        tn = cm.sum() - (tp + fp + fn)\n",
        "\n",
        "        # specyficzność = TN / (TN + FP) z mechanizm uniknięcia dzielenia przez 0\n",
        "        if (tn + fp) > 0:\n",
        "            spec = tn / (tn + fp)\n",
        "        else:\n",
        "            spec = 0.0\n",
        "        specificity_per_class.append(spec)\n",
        "\n",
        "    return np.mean(specificity_per_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdvXnkm9LgUu"
      },
      "outputs": [],
      "source": [
        "def train_and_tune_classifier(name, clf_obj, param_dist, X_train, y_train):\n",
        "    \"\"\"\n",
        "    Przeprowadza optymalizację hiperparametrów i trening końcowy klasyfikatora.\n",
        "\n",
        "    Funkcja wykorzystuje RandomizedSearchCV (losowe przeszukiwanie przestrzeni parametrów)\n",
        "    z 3-krotną walidacją krzyżową, aby znaleźć najlepszą konfigurację modelu,\n",
        "    a następnie zwraca estymator wytrenowany na pełnym zbiorze treningowym.\n",
        "\n",
        "    Args:\n",
        "        name (str): Nazwa modelu (np. 'SVM'), używana do logowania postępu.\n",
        "        clf_obj (sklearn.base.BaseEstimator): Instancja klasyfikatora (np. SVC, RandomForestClassifier).\n",
        "        param_dist (dict): Przestrzeń hiperparametrów do przeszukania (słownik lub rozkłady).\n",
        "        X_train (np.ndarray): Macierz cech treningowych.\n",
        "        y_train (np.ndarray): Wektor etykiet treningowych.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Krotka (best_estimator, best_params, duration), gdzie:\n",
        "               - best_estimator: Najlepszy, wytrenowany model gotowy do predykcji.\n",
        "               - best_params (dict): Słownik z najlepszymi znalezionymi parametrami.\n",
        "               - duration (float): Czas trwania procesu strojenia (w sekundach).\n",
        "    \"\"\"\n",
        "    print(f\"\\nTrening i dostrajanie {name}\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # dostrajanie hiperparametrów\n",
        "    search = RandomizedSearchCV(\n",
        "        clf_obj,\n",
        "        param_dist,\n",
        "        n_iter=15,\n",
        "        cv=3,\n",
        "        n_jobs=-1,\n",
        "        random_state=SEED,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # trening najlepszego modelu\n",
        "    search.fit(X_train, y_train)\n",
        "    duration = time.time() - start_time\n",
        "\n",
        "    return search.best_estimator_, search.best_params_, duration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IL_c8485IF3G"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate_classifiers(X_train, y_train, X_val, y_val, fold_idx, extraction_time):\n",
        "    \"\"\"\n",
        "    Zarządza procesem treningu, walidacji i raportowania dla klasyfikatorów klasycznych (hybrydowych).\n",
        "\n",
        "    Funkcja iteruje przez zdefiniowaną listę modeli (SVM, Las Losowy) i dla każdego z nich:\n",
        "    1. Uruchamia procedurę strojenia hiperparametrów (np. RandomizedSearchCV) i treningu.\n",
        "    2. Zachowuje najlepszy znaleziony model (estymator).\n",
        "    3. Wykonuje predykcję na zbiorze walidacyjnym.\n",
        "    4. Oblicza zestaw metryk diagnostycznych (MCC, czułość, specyficzność, precyzja, dokładność).\n",
        "    5. Agreguje wyniki, predykcje oraz obiekty modeli w struktury gotowe do zwrotu.\n",
        "\n",
        "    Args:\n",
        "        X_train (np.ndarray): Macierz cech zbioru treningowego (wyekstrahowana z CNN).\n",
        "        y_train (np.ndarray): Wektor etykiet zbioru treningowego.\n",
        "        X_val (np.ndarray): Macierz cech zbioru walidacyjnego.\n",
        "        y_val (np.ndarray): Wektor etykiet zbioru walidacyjnego.\n",
        "        fold_idx (int): Numer bieżącego foldu (używany do logowania wyników).\n",
        "        extraction_time (float): Czas [s] zużyty na ekstrakcję cech (dodawany do czasu treningu klasyfikatora).\n",
        "\n",
        "    Returns:\n",
        "        tuple: Krotka (fold_results, fold_preds, trained_models), zawierająca:\n",
        "            - fold_results (list): Lista słowników z obliczonymi metrykami i najlepszymi parametrami.\n",
        "            - fold_preds (dict): Słownik zawierający listy etykiet prawdziwych i przewidzianych\n",
        "              (struktura: {'NazwaModelu': {'y_true': [...], 'y_pred': [...]}}).\n",
        "            - trained_models (dict): Słownik zawierający wytrenowane obiekty modeli (np. sklearn.svm.SVC),\n",
        "              gotowe do zapisu (dump) lub dalszej inferencji.\n",
        "    \"\"\"\n",
        "\n",
        "    # definiujemy modele\n",
        "    classifiers = [\n",
        "        ('SVM', SVC(probability=True, random_state=SEED, cache_size=2000, max_iter=3000), param_dist_svm),\n",
        "        ('Las losowy', RandomForestClassifier(random_state=SEED, n_jobs=None), param_dist_rf)\n",
        "    ]\n",
        "\n",
        "    fold_results = []\n",
        "    fold_preds = {'SVM': {'y_true': [], 'y_pred': []}, 'Las losowy': {'y_true': [], 'y_pred': []}}\n",
        "    trained_models = {} # słownik na modele\n",
        "\n",
        "    for name, clf_obj, param_dist in classifiers:\n",
        "        # trening\n",
        "        best_model, best_params, train_time = train_and_tune_classifier(\n",
        "            name, clf_obj, param_dist, X_train, y_train\n",
        "        )\n",
        "\n",
        "        # zapisujemy model\n",
        "        trained_models[name] = best_model\n",
        "\n",
        "        # całkowity czas treningu (ekstrakcja + trening)\n",
        "        total_time = extraction_time + train_time\n",
        "\n",
        "        # predykcja\n",
        "        preds = best_model.predict(X_val)\n",
        "\n",
        "        # obliczanie metryk\n",
        "        acc = accuracy_score(y_val, preds)\n",
        "        mcc = matthews_corrcoef(y_val, preds)\n",
        "        sens = recall_score(y_val, preds, average='macro', zero_division=0)\n",
        "        prec = precision_score(y_val, preds, average='macro', zero_division=0)\n",
        "        spec = calculate_specificity(y_val, preds, NUM_CLASSES)\n",
        "\n",
        "        print(f\"Wynik dla {name}:\")\n",
        "        print(f\"\\tMCC = {mcc:.4f}\")\n",
        "        print(f\"\\tCzułość = {sens:.4f}\")\n",
        "        print(f\"\\tDokładność = {acc:.4f}\")\n",
        "        print(f\"\\tSpecyficzność = {spec:.4f}\")\n",
        "        print(f\"\\tPrecyzja = {prec:.4f}\")\n",
        "\n",
        "        # zapis wyników\n",
        "        fold_results.append({\n",
        "            'fold': fold_idx,\n",
        "            'model': name,\n",
        "            'val_dokładność': acc,\n",
        "            'val_mcc': mcc,\n",
        "            'val_czułość': sens,\n",
        "            'val_specyficzność': spec,\n",
        "            'val_precyzja': prec,\n",
        "            'czas_trwania_foldu': total_time,\n",
        "            'najlepsze_parametry': best_params\n",
        "        })\n",
        "\n",
        "        fold_preds[name]['y_true'].extend(y_val.tolist())\n",
        "        fold_preds[name]['y_pred'].extend(preds.tolist())\n",
        "\n",
        "    return fold_results, fold_preds, trained_models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWjXduxGg03Q"
      },
      "source": [
        "## Trening modeli hybrydowych"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO5RikgPgfDO"
      },
      "source": [
        "Możemy teraz przejść do przeprowadzenia pełnego treningu modeli hybrydowych. Wprowadzamy zabezpieczenia na wypadek przerwania sesji i utraty wyników."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIc10MPDIIAq",
        "outputId": "39bd781b-c99d-4fb5-c8c3-47de9a37e24e"
      },
      "outputs": [],
      "source": [
        "hybrid_results = []\n",
        "all_hybrid_preds = {\n",
        "    'SVM': {'y_true': [], 'y_pred': []},\n",
        "    'Las losowy': {'y_true': [], 'y_pred': []}\n",
        "}\n",
        "\n",
        "print(f\"Rozpoczynam trening hybrydowy ({CV_FOLDS} foldów)...\")\n",
        "\n",
        "for fold_idx in range(CV_FOLDS):\n",
        "    # definiujemy ścieżki plików\n",
        "    results_path = os.path.join(RESULTS_DIR, f'wyniki_modeli_hybrydowych_fold_{fold_idx}.json')\n",
        "    preds_path = os.path.join(RESULTS_DIR, f'predykcje_modeli_hybrydowych_fold_{fold_idx}.json')\n",
        "\n",
        "    # definiujemy ścieżki modeli\n",
        "    svm_path = os.path.join(MODELS_DIR, f'svm_fold_{fold_idx}.pkl')\n",
        "    rf_path = os.path.join(MODELS_DIR, f'rf_fold_{fold_idx}.pkl')\n",
        "\n",
        "    # definiujemy ścieżkę do tymczasowego pliku z cechami\n",
        "    features_cache_path = os.path.join(RESULTS_DIR, f'features_cache_fold_{fold_idx}.npz')\n",
        "\n",
        "    # MECHANIZM WZNAWIANIA\n",
        "    if os.path.exists(results_path) and os.path.exists(preds_path) and os.path.exists(svm_path) and os.path.exists(rf_path):\n",
        "\n",
        "        print(f\"\\n[INFO] Fold {fold_idx} ukończony. Wczytuję wyniki.\")\n",
        "\n",
        "        # wczytujemy wyniki\n",
        "        with open(results_path, 'r') as f:\n",
        "            fold_res = json.load(f)\n",
        "            hybrid_results.extend(fold_res) # dodajemy do głównej listy\n",
        "\n",
        "        # wczytujemy predykcje\n",
        "        with open(preds_path, 'r') as f:\n",
        "            fold_preds_loaded = json.load(f)\n",
        "            for model_name in ['SVM', 'Las losowy']:\n",
        "                all_hybrid_preds[model_name]['y_true'].extend(fold_preds_loaded[model_name]['y_true'])\n",
        "                all_hybrid_preds[model_name]['y_pred'].extend(fold_preds_loaded[model_name]['y_pred'])\n",
        "\n",
        "        continue # przejście do kolejnego foldu\n",
        "\n",
        "    print(f\"\\n{'='*5}FOLD {fold_idx}/{CV_FOLDS - 1}{'='*5}\")\n",
        "\n",
        "    # MECHANIZM EKSTRAKCJI CECH\n",
        "    if os.path.exists(features_cache_path):\n",
        "        print(f\"[CACHE] Znaleziono zapisane cechy. Wczytuję z: {features_cache_path}\")\n",
        "\n",
        "        # wczytanie tablic NumPy\n",
        "        data = np.load(features_cache_path)\n",
        "        X_train = data['X_train']\n",
        "        y_train = data['y_train']\n",
        "        X_val = data['X_val']\n",
        "        y_val = data['y_val']\n",
        "        extraction_time = float(data['extraction_time'])\n",
        "\n",
        "    else:\n",
        "        print(f\"[GPU] Cache nie istnieje. Uruchamiam ekstrakcję cech.\")\n",
        "\n",
        "        # wczytujemy model\n",
        "        model_extractor = load_feature_extractor(fold_idx)\n",
        "        if model_extractor is None:\n",
        "            print(f\"BŁĄD KRYTYCZNY: Brak modelu DenseNet dla foldu {fold_idx}!\")\n",
        "            break\n",
        "\n",
        "        # przygotowujemy dane\n",
        "        train_loader, val_loader = get_fold_data(df, fold_idx)\n",
        "\n",
        "        # wyciągamy cechy i standaryzujemy\n",
        "        X_train, y_train, X_val, y_val, extraction_time = process_features(model_extractor, train_loader, val_loader, fold_idx)\n",
        "\n",
        "        # czyścimy pamięć\n",
        "        del model_extractor\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        # zapisujemy cechy do pliku tymczasowego\n",
        "        print(f\"[CACHE] Zapisuję cechy na dysk.\")\n",
        "        np.savez_compressed(\n",
        "            features_cache_path,\n",
        "            X_train=X_train, y_train=y_train,\n",
        "            X_val=X_val, y_val=y_val,\n",
        "            extraction_time=extraction_time\n",
        "        )\n",
        "\n",
        "    # trenujemy i ewaluujemy klasyfikatory\n",
        "    fold_res, fold_preds_dict, trained_models_dict = train_and_evaluate_classifiers(\n",
        "        X_train, y_train, X_val, y_val, fold_idx, extraction_time\n",
        "    )\n",
        "\n",
        "    # zbieramy wyniki i predykcje walidacyjne\n",
        "    hybrid_results.extend(fold_res)\n",
        "    for model_name in ['SVM', 'Las losowy']:\n",
        "        all_hybrid_preds[model_name]['y_true'].extend(fold_preds_dict[model_name]['y_true'])\n",
        "        all_hybrid_preds[model_name]['y_pred'].extend(fold_preds_dict[model_name]['y_pred'])\n",
        "\n",
        "    # zapisujemy wyniki foldu\n",
        "    with open(results_path, 'w') as f:\n",
        "        json.dump(fold_res, f)\n",
        "\n",
        "    # zapisujemy predykcje foldu\n",
        "    with open(preds_path, 'w') as f:\n",
        "        json.dump(fold_preds_dict, f)\n",
        "\n",
        "    # zapisujemy parametry modelu\n",
        "    joblib.dump(trained_models_dict['SVM'], svm_path)\n",
        "    joblib.dump(trained_models_dict['Las losowy'], rf_path)\n",
        "\n",
        "\n",
        "print(f\"{'#'*5} Zakończono trening modeli hybrydowych. {'='*5}\")\n",
        "\n",
        "# zapisujemy zbiorcze wyniki\n",
        "with open(os.path.join(RESULTS_DIR, 'wyniki_modeli_hybrydowych_FULL.json'), 'w') as f:\n",
        "    json.dump(hybrid_results, f)\n",
        "\n",
        "# zapisujemy zbiorcze predykcje\n",
        "with open(os.path.join(RESULTS_DIR, 'predykcje_modeli_hybrydowych_FULL.json'), 'w') as f:\n",
        "    json.dump(all_hybrid_preds, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dupQxDW7hAg6"
      },
      "source": [
        "Zobaczmy na wyniki treningu. Będą to średnie wyniki z wszystkich podzbiorów."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "mItkoMXEgTYW",
        "outputId": "f4fbedb9-e1e0-4e37-eb40-4902f3bd939c"
      },
      "outputs": [],
      "source": [
        "results_df = pd.DataFrame(hybrid_results)\n",
        "summary = results_df.groupby('model')[['val_dokładność', 'val_mcc', 'val_czułość', 'val_specyficzność', 'val_precyzja', 'czas_trwania_foldu']].mean()\n",
        "\n",
        "summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig1Addx2g9Wh"
      },
      "source": [
        "## Wizualizacja wyników treningu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kw6CamahhA6"
      },
      "source": [
        "Spróbujemy zwizualizować wyniki treningu. W tym przypadku nie narysujemy klasycznych krzywych uczenia, ale za to możemy przyglądnąć się macierzy pomyłek i wartość czułości i specyficzności."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_YP3GOmjNlN"
      },
      "outputs": [],
      "source": [
        "def get_class_names_from_df(df):\n",
        "    \"\"\"\n",
        "    Pobiera listę nazw klas posortowaną zgodnie z ich numerycznymi identyfikatorami.\n",
        "\n",
        "    Funkcja tworzy mapowanie między kolumną 'target' (0, 1, 2...) a 'typ_zmiany' (nazwa choroby),\n",
        "    gwarantując, że kolejność nazw na liście odpowiada kolejności wyjść modelu.\n",
        "    Jest to niezbędne do poprawnego opisywania osi macierzy pomyłek.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): Ramka danych zawierająca kolumny 'target' (int) i 'typ_zmiany' (str).\n",
        "\n",
        "    Returns:\n",
        "        list: Lista nazw chorób (str), gdzie indeks elementu odpowiada wartości targetu (np. list[0] to nazwa dla target=0).\n",
        "    \"\"\"\n",
        "    # sortujemy po target, żeby indeks 0 listy odpowiadał target=0\n",
        "    sorted_classes = df[['target', 'typ_zmiany']].drop_duplicates().sort_values('target')\n",
        "    return sorted_classes['typ_zmiany'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgaAwmwHjXhy"
      },
      "outputs": [],
      "source": [
        "def plot_validation_diagnosis(all_preds_dict, hybrid_results_list, df, output_dir):\n",
        "    \"\"\"\n",
        "    Generuje i zapisuje graficzne podsumowanie wyników walidacji krzyżowej.\n",
        "\n",
        "    Funkcja tworzy dwa rodzaje wykresów diagnostycznych:\n",
        "    1. Znormalizowane macierze pomyłek - zsumowane\n",
        "       ze wszystkich foldów, pozwalające ocenić ogólną skuteczność diagnozy per klasa.\n",
        "    2. Wykres rozrzutu Czułość vs Specyficzność - obrazujący stabilność\n",
        "       modeli pomiędzy foldami oraz ich średni punkt pracy (kompromis).\n",
        "\n",
        "    Args:\n",
        "        all_preds_dict (dict): Słownik zawierający listy 'y_true' i 'y_pred' dla każdego modelu.\n",
        "        hybrid_results_list (list): Lista słowników z metrykami dla każdego foldu.\n",
        "        df (pd.DataFrame): Główna ramka danych (służy do automatycznego pobrania nazw klas).\n",
        "        output_dir (str): Ścieżka do katalogu, w którym zostaną zapisane pliki PNG.\n",
        "    \"\"\"\n",
        "    # ustalenie nazw klas\n",
        "    try:\n",
        "        class_names = get_class_names_from_df(df)\n",
        "        print(f\"Automatycznie wykryto klasy: {class_names}\")\n",
        "    except KeyError:\n",
        "        # gdyby nazwy kolumn były inne\n",
        "        print(\"[Ostrzeżenie] Nie znaleziono kolumny 'diagnosis'. Używam domyślnych.\")\n",
        "        class_names = ['AK', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'SCC', 'VASC']\n",
        "\n",
        "    models = list(all_preds_dict.keys())\n",
        "\n",
        "    # rysujemy macierze pomyłek\n",
        "    fig, axes = plt.subplots(1, len(models), figsize=(8 * len(models), 7))\n",
        "    if len(models) == 1: axes = [axes] # Obsługa przypadku jednego modelu\n",
        "\n",
        "    for idx, model_name in enumerate(models):\n",
        "        y_true = all_preds_dict[model_name]['y_true']\n",
        "        y_pred = all_preds_dict[model_name]['y_pred']\n",
        "\n",
        "        # obliczamy macierz\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "        # normalizujemy (żeby widzieć skuteczność w %)\n",
        "        with np.errstate(divide='ignore', invalid='ignore'):\n",
        "            cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "            cm_norm = np.nan_to_num(cm_norm) # Zamienia NaN na 0\n",
        "\n",
        "        sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Blues',\n",
        "                    xticklabels=class_names, yticklabels=class_names,\n",
        "                    ax=axes[idx], cbar=False, annot_kws={\"size\": 9})\n",
        "\n",
        "        axes[idx].set_title(f'{model_name}\\nMacierz pomyłek (zsumowana z 5 foldów)', fontsize=12)\n",
        "        axes[idx].set_ylabel('Prawdziwa diagnoza')\n",
        "        axes[idx].set_xlabel('Przewidziana diagnoza')\n",
        "        axes[idx].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # zapisujemy wykres\n",
        "    save_cm_path = os.path.join(output_dir, 'walidacja_macierze_pomylek.png')\n",
        "    plt.savefig(save_cm_path)\n",
        "    print(f\"Zapisano macierze pomyłek: {save_cm_path}\")\n",
        "    plt.show()\n",
        "\n",
        "    # wykres rozrzutu: Czułość vs Specyficzność\n",
        "    results_df = pd.DataFrame(hybrid_results_list)\n",
        "\n",
        "    plt.figure(figsize=(10, 7))\n",
        "\n",
        "    # rysujemy punkty\n",
        "    sns.scatterplot(\n",
        "        data=results_df,\n",
        "        x='val_specyficzność',\n",
        "        y='val_czułość',\n",
        "        hue='model',\n",
        "        style='model',\n",
        "        s=150,\n",
        "        palette='viridis',\n",
        "        alpha=0.8\n",
        "    )\n",
        "\n",
        "    # rysujemy średnie jako większe punkty (krzyżyki)\n",
        "    means = results_df.groupby('model')[['val_specyficzność', 'val_czułość']].mean()\n",
        "    for name, row in means.iterrows():\n",
        "        plt.scatter(row['val_specyficzność'], row['val_czułość'], marker='+', s=400, color='red', linewidth=3, label=f'Średnia {name}')\n",
        "\n",
        "    # linie pomocnicze\n",
        "    plt.axhline(0.5, color='gray', linestyle='--', alpha=0.3)\n",
        "    plt.axvline(0.8, color='gray', linestyle='--', alpha=0.3)\n",
        "    plt.title('Czułość vs Specyficzność', fontsize=14)\n",
        "    plt.xlabel('Specyficzność', fontsize=12)\n",
        "    plt.ylabel('Czułość', fontsize=12)\n",
        "\n",
        "    # legenda\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # zapisujemy wykres\n",
        "    save_sc_path = os.path.join(output_dir, 'walidacja_scatter_sens_spec.png')\n",
        "    plt.savefig(save_sc_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"Zapisano wykres scatter: {save_sc_path}\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BV6TWdK4R72-",
        "outputId": "f5832f26-7b31-451a-e103-135874cc4183"
      },
      "outputs": [],
      "source": [
        "plot_validation_diagnosis(all_hybrid_preds, hybrid_results, df, RESULTS_DIR)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSG7cA0wC1Ry"
      },
      "source": [
        "# Diagnostyka raka skóry z wykorzystaniem analizy obrazów dermatologicznych - przygotowanie i analiza danych"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrOGDcTkC3oK"
      },
      "source": [
        "Celem tego notatnika jest zapoznanie się z danym zbioru ISIC2019 oraz przygotowanie ich do dalszej pracy, czyli do trenowania i porównywania modeli DenseNet-121, DenseNet + SVM i DenseNet + RF. W tym notatniku przeanalizujemy metadane, przygotujemy obrazy do treningu oraz przetestujemy elementy potoku procesu treningu (podział z użyciem `StratifiedGroupKFold`, klasy `Dataset` i `DataLoader`). Końcowym efektem będzą odpowiednio przygotowane i podzielone dane do treningu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cJm8r1LDyKN"
      },
      "source": [
        "## Konfiguracja środowiska"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCmUhmp3D9sf"
      },
      "source": [
        "Importujemy potrzebne biblioteki.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73Pv3ItgAuXv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive, files\n",
        "import kagglehub\n",
        "import joblib\n",
        "import json\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "import multiprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KyzLwk-EAOE"
      },
      "source": [
        "Definiujemy zmienne globalne."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CrYdaauEGG0"
      },
      "outputs": [],
      "source": [
        "# parametry treningu\n",
        "SEED = 42\n",
        "BATCH_SIZE = 64                                   # wielkość partii danych\n",
        "NUM_WORKERS = min(4, multiprocessing.cpu_count()) # liczba wątków procesora\n",
        "\n",
        "# parametry transformacji obrazów\n",
        "IMG_SIZE = 300                      # wymiar wejściowy obrazu\n",
        "NORM_MEAN = [0.485, 0.456, 0.406]   # wartości średniej do normalizacji\n",
        "NORM_STD = [0.229, 0.224, 0.225]    # wartości odchyleń do normalizacji\n",
        "\n",
        "# parametry czyszczenia danych\n",
        "VIGNETTE_THRESHOLD = 20      # próg czerni\n",
        "EXTRA_CROP = 0.05            # margines dodatkowego przycięcia (5%)\n",
        "MIN_FILL_RATIO = 0.95        # bezpiecznik dla zdjęć pełnokadrowych\n",
        "\n",
        "# podział danych\n",
        "TEST_SPLIT = 10              # 1/10 danych na zbiór testowy\n",
        "CV_FOLDS = 5                 # liczba foldów walidacyjnych\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zd5u8JtrEe3X"
      },
      "source": [
        "Ustawiamy ziarno losości dla powtarzalności wyników."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGSwkv_CEiKR"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed=42):\n",
        "    \"\"\"Ustawia ziarno losowości dla reprodukowalności wyników.\"\"\"\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fa8ag_lCEnBt"
      },
      "outputs": [],
      "source": [
        "set_seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qn4NhEZbEqix"
      },
      "source": [
        "Dodatkowo konfigurujemy wygląd wykresów w całym notatniku."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzEu2uQbEuHu"
      },
      "outputs": [],
      "source": [
        "# bazowy styl seaborn\n",
        "sns.set_theme(style=\"whitegrid\", context=\"notebook\", font_scale=1.1)\n",
        "\n",
        "# konfiguracja parametrów matplotlib\n",
        "plt.rcParams.update({\n",
        "    # wymiary i jakość\n",
        "    'figure.figsize': (10, 6),       # domyślny rozmiar\n",
        "    'figure.dpi': 120,               # podgląd na ekranie\n",
        "    'savefig.dpi': 300,              # jakość do druku\n",
        "    'savefig.bbox': 'tight',         # automatyczne przycinanie marginesów przy zapisie\n",
        "    'savefig.pad_inches': 0.1,       # mały bufor wokół przyciętego obrazka\n",
        "\n",
        "    # tekst i czcionki\n",
        "    'font.family': 'sans-serif',\n",
        "    'font.sans-serif': ['Arial', 'DejaVu Sans', 'Liberation Sans'],\n",
        "    'axes.labelsize': 15,            # rozmiar nazw osi\n",
        "    'axes.titlesize': 20,            # rozmiar tytułu wykresu\n",
        "    'xtick.labelsize': 11,           # rozmiar liczb na osi X\n",
        "    'ytick.labelsize': 11,           # rozmiar liczb na osi Y\n",
        "    'legend.fontsize': 11,           # rozmiar tekstu w legendzie\n",
        "\n",
        "    # linie i siatka\n",
        "    'lines.linewidth': 2.5,          # grubsze linie\n",
        "    'lines.markersize': 8,           # nieco większe kropki/punkty\n",
        "    'grid.color': '#f0f0f0',         # bardzo jasna szarość siatki\n",
        "    'grid.linewidth': 1.0,\n",
        "    'axes.axisbelow': True,          # siatka pod spodem, dane na wierzchu!\n",
        "\n",
        "    # estetyka ramki\n",
        "    'axes.spines.top': False,        # usuń górną ramkę\n",
        "    'axes.spines.right': False,      # usuń prawą ramkę\n",
        "    'axes.linewidth': 1.2,           # grubość osi X i Y\n",
        "    'legend.frameon': True,          # włącz ramkę legendy\n",
        "    'legend.framealpha': 0.95,       # białe tło legendy\n",
        "    'legend.facecolor': 'white'\n",
        "})\n",
        "\n",
        "# wyostrzenie w Colab\n",
        "%config InlineBackend.figure_format = 'retina'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkZQZiqPFBBl"
      },
      "source": [
        "Konfigurujemy wszelki potrzebne ścieżki."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlzvcBdMFDot",
        "outputId": "0be91507-b03b-431b-a0ec-1c9dd9668a98"
      },
      "outputs": [],
      "source": [
        "# montowanie Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# podajemy nazwę głównego folderu projektu\n",
        "PROJECT_FOLDER_NAME = 'Implementacja'\n",
        "BASE_DIR = os.path.join('/content/drive/MyDrive/Diagnostyka raka skóry z wykorzystaniem analizy obrazów dermatologicznych', PROJECT_FOLDER_NAME)\n",
        "\n",
        "# podajemy ścieżkę w Colabie do zapisania pobieranych danych\n",
        "DATA_ROOT_DIR = '/content/ISIC2019'\n",
        "IMG_DIR = os.path.join(DATA_ROOT_DIR, 'images')\n",
        "PROCESSED_DIR = os.path.join(DATA_ROOT_DIR, 'images_processed')\n",
        "\n",
        "# definijemy podfoldery\n",
        "MODELS_DIR = os.path.join(BASE_DIR, 'Modele')\n",
        "RESULTS_DIR = os.path.join(BASE_DIR, 'Wyniki')\n",
        "DATA_DIR = os.path.join(BASE_DIR, 'Dane')\n",
        "\n",
        "# tworzymy foldery na Google Drive (jeśli nie istnieją)\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Katalog roboczy projektu: {BASE_DIR}\")\n",
        "print(f\"Dane będą zapisywane w: {DATA_ROOT_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zr3ChlXWFbO3"
      },
      "source": [
        "### Konfiguracja Kaggle API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azMTHWblGBT1"
      },
      "source": [
        "Kaggle API jest nam potrzebne do pobrania danych bezpośrednio do notatnika. Folder ZIP jest bardzo obszernym plikiem i ręczne wgrywanie go na Google Drive może zająć bardzo dużo czasu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ffiDwLzFMnb"
      },
      "source": [
        "Kofigurujemy ścieżkę dla Kaggle API. Klucz będzie zapisywany bezpośrednio w folderze projektu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqsvrXpRFHsC"
      },
      "outputs": [],
      "source": [
        "kaggle_key_drive_path = os.path.join(BASE_DIR, 'kaggle.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOc6GpD1FPM7"
      },
      "source": [
        "Tworzymy w Colabie folder na plik z Kaggle API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7K7Fm4wFJb2"
      },
      "outputs": [],
      "source": [
        "kaggle_sys_dir = '/root/.kaggle'\n",
        "os.makedirs(kaggle_sys_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PO1ULcWQFilx"
      },
      "source": [
        "Wprowadzamy Kaggle API. Klucz ten należy utworzyć indywidualnie dla każdego użytkownika notatników z implementacją pracy inżynierskie. Aby go zdobyć należy:\n",
        "1. Zalogować się na swój profil na stronie Kaggle.\n",
        "2. Wejście w ustawienia swojego profilu (kilkamy na swoje zdjęcie profilowe i wybieramy ,,Settings'').\n",
        "3. W sekcji ,,API'' klikamy ,,Generate New Token'', następnie wprowadzamy nazwę tokenu i klikamy ,,Generate''.\n",
        "4. Kopiujemy kod z okienka ,,API TOKEN''.\n",
        "5. W dowolnym edytorze tekstu (np. Notatniku) wprowadzamy tekst o następującej strykturze\n",
        "$$\\{\\text{\"username\":\"nazwa_uzytkownika_kaggle\",\"key\":\"skopiowane_kaggle_api\"}\\}$$\n",
        "i zapisujemy plik jako ,,kaggle.json''.\n",
        "W poniższej funkcji zostaniemy poproszeni o wgranie utworzonego pliku.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1K0_6fwrFe48"
      },
      "outputs": [],
      "source": [
        "# sprawdzamy czy klucz jest już na Drive\n",
        "if not os.path.exists(kaggle_key_drive_path):\n",
        "    print(f\"UWAGA: Nie znaleziono pliku kaggle.json w lokalizacji: {kaggle_key_drive_path}\")\n",
        "    print(\"Proszę przesłać plik kaggle.json teraz (zostanie zapisany na Drive):\")\n",
        "\n",
        "    # przesyłamy plik kaggle.json\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for filename in uploaded.keys():\n",
        "        if filename == 'kaggle.json':\n",
        "            # zapisujemy trwale na Google Drive\n",
        "            with open(kaggle_key_drive_path, 'wb') as f:\n",
        "                f.write(uploaded[filename])\n",
        "            print(f\"Zapisano kaggle.json w: {kaggle_key_drive_path}\")\n",
        "        else:\n",
        "            print(f\"Pominięto plik: {filename} (oczekiwano kaggle.json)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SyLYvhyE2OI"
      },
      "source": [
        "## Pobranie danych"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0qLTpsxFm_E"
      },
      "source": [
        "Pobieramy, rozpakowujemy i porządkujemy zbiór ISIC2019. Nie pobieramy obrazów na dysk Google Drive, lecz do pamięci Google Colab. Pozwoli to na sprawniejsze wczytywanie plików w notatniku."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gopZgAKE5Ho",
        "outputId": "ffedaf49-60a5-495b-e5ab-01ea0c3a9a8e"
      },
      "outputs": [],
      "source": [
        "if os.path.exists(kaggle_key_drive_path):\n",
        "    # instalacja klucza w systemie\n",
        "    shutil.copy(kaggle_key_drive_path, os.path.join(kaggle_sys_dir, 'kaggle.json'))\n",
        "    os.chmod(os.path.join(kaggle_sys_dir, 'kaggle.json'), 600)\n",
        "    print(\"Klucz Kaggle API skonfigurowany.\")\n",
        "\n",
        "    # POBIERANIE I PORZĄDKOWANIE DANYCH\n",
        "\n",
        "    # sprawdzamy, czy folder ze zdjęciami już istnieje i jest pełny\n",
        "    # (np. czy nie uruchamiamy komórki drugi raz w tej samej sesji)\n",
        "    if not os.path.exists(IMG_DIR):\n",
        "        print(\"\\nPobieranie danych z Kaggle...\")\n",
        "        # pobieramy do folderu tymczasowego\n",
        "        path = kagglehub.dataset_download(\"andrewmvd/isic-2019\")\n",
        "        print(f\"Pobrano dane do folderu tymczasowego: {path}\")\n",
        "\n",
        "        # tworzymy docelowe foldery na obrazy\n",
        "        os.makedirs(IMG_DIR, exist_ok=True)\n",
        "        os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
        "\n",
        "        # przenosimy metadane w folderu z danymi w Colabie\n",
        "        for csv_file in glob.glob(os.path.join(path, \"*.csv\")):\n",
        "            shutil.copy(csv_file, DATA_ROOT_DIR)\n",
        "            print(f\"Przeniesiono: {os.path.basename(csv_file)}\")\n",
        "\n",
        "        # szukamy rekursywnie zdjęć we wszystkich podfolderach pobranych danych\n",
        "        jpg_files = glob.glob(os.path.join(path, \"**\", \"*.jpg\"), recursive=True)\n",
        "\n",
        "        print(f\"Znaleziono {len(jpg_files)} zdjęć.\")\n",
        "\n",
        "        for file_path in tqdm(jpg_files, desc=\"Kopiowanie zdjęć\", unit=\"plik\"):\n",
        "            # przenosimy plik do wspólnego folderu\n",
        "            shutil.copy(file_path, os.path.join(IMG_DIR, os.path.basename(file_path)))\n",
        "        print(\"Przeniesiono zdjęcia do folderu z danymi.\")\n",
        "\n",
        "        # weryfikujemy liczbę plików\n",
        "        num_images = len(os.listdir(IMG_DIR))\n",
        "        print(f\"\\nSUKCES: Dane gotowe w {DATA_ROOT_DIR}\")\n",
        "        print(f\"Liczba zdjęć w {IMG_DIR}: {num_images}\")\n",
        "\n",
        "    else:\n",
        "        print(\"Dane są już pobrane i uporządkowane.\")\n",
        "        print(f\"Lokalizacja zdjęć: {IMG_DIR}\")\n",
        "\n",
        "else:\n",
        "    print(\"BŁĄD: Brak pliku kaggle.json. Nie można pobrać danych.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5rsq0QOFuqC"
      },
      "source": [
        "## Analiza metadanych"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsNdYaH4GfEw"
      },
      "source": [
        "Wczytujemy metadane i sprawdzamy informacje o nich."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5_RHTnFFwgK"
      },
      "outputs": [],
      "source": [
        "# ścieżki do metadanych\n",
        "meta_path = os.path.join(DATA_ROOT_DIR, 'ISIC_2019_Training_Metadata.csv')\n",
        "gt_path = os.path.join(DATA_ROOT_DIR, 'ISIC_2019_Training_GroundTruth.csv')\n",
        "\n",
        "df_meta = pd.read_csv(meta_path)\n",
        "df_gt = pd.read_csv(gt_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ev5yRwWwGyb5",
        "outputId": "428bdce7-969e-48fd-9698-7d6a61c092f7"
      },
      "outputs": [],
      "source": [
        "df_meta.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Zkopg9p7G1Bu",
        "outputId": "06ff9674-f342-4c10-d435-4059c6a39f5b"
      },
      "outputs": [],
      "source": [
        "df_gt.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlCsuXzsG31R",
        "outputId": "c4e86243-87eb-4d1a-8c4e-7afa52a4584e"
      },
      "outputs": [],
      "source": [
        "df_meta.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgLNLNg2G52k",
        "outputId": "199c3448-82cc-430f-a540-bae249eeac9e"
      },
      "outputs": [],
      "source": [
        "df_gt.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_y3ZIT0RG8f2"
      },
      "source": [
        "Zauważmy, że obie tabele mają wspólną kolumnę, zatem połączmy je w jeden plik z metadanymi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "merZbnfwHZu6",
        "outputId": "0bdc04b6-43e2-43a9-c13f-396074a22c91"
      },
      "outputs": [],
      "source": [
        "df = pd.merge(df_meta, df_gt, on='image', how='inner')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtpPIe-bHb4b",
        "outputId": "5ec0abac-68fa-4c7f-a7e7-f57535edaf84"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnTrVCwNHfeu"
      },
      "source": [
        "Zauważmy, że mamy 25331 wierszy (tym samym tyle obrazów). Mamy jedyną kolumnę liczbową `age_approx`. Możemy zauważyć, że poza kolumną `image` mam do czynienia z brakami."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tw2bUY_-HhCl"
      },
      "source": [
        "### Czyszczenie metadanych"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lX-iPr1Hlky"
      },
      "source": [
        "Zajmijmy się najpierw uzupełnieniem braków. Zacznijmy od kolumny `lesion_id`. Zobaczmy na unikalne wartości tej kolumny."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDvqfE0NHgNf",
        "outputId": "4a42e09c-3188-4c1b-a93d-8cd938d0f039"
      },
      "outputs": [],
      "source": [
        "df['lesion_id'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amMHU3oEHpyC",
        "outputId": "218be21c-c3d3-4d07-a526-dc799fdda97a"
      },
      "outputs": [],
      "source": [
        "df['lesion_id'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8cNDLxMHsI4"
      },
      "source": [
        "Zauważmy, że mamy 11847 unikalnych wartości w tej kolumnie. Oznacza to, że są zdjęcia, które przedstawiają tę samą zmianę lub są to zmiany jednego pacjenta. Załóżmy zatem, że braki obecne w tej kolumnie są unikalnymi zmianami. Pozwoli nam to zachować te zdjęcia w zbiorze. Braki w uzupełnimi odpowiednią wartością z kolumny `image`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hA5kz8sVH95N",
        "outputId": "27d4e4c9-b8f2-4899-89db-e3bdb0feaa9d"
      },
      "outputs": [],
      "source": [
        "df['lesion_id'] = df['lesion_id'].fillna(df['image'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzVZCa_1IF8W"
      },
      "source": [
        "W kolumnie `anatom_site_general` zawarte są informacje o położeniu zmiany. Możemy zatem uzupełnić braki wartością `unknown`, gdyż zakładamy, że przy tych zmianach nie podano informacji o położeniu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5Wh2GDGXIIU_",
        "outputId": "99dd9e2d-736c-4fd0-c2e6-cc7798315701"
      },
      "outputs": [],
      "source": [
        "df['anatom_site_general'] = df['anatom_site_general'].fillna('unknown')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AqPC464IK3R"
      },
      "source": [
        "Podobnie postępujemy z kolumną `sex`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7MJ9Z1PMIOMm",
        "outputId": "7792551c-022d-413f-9be9-472efe81fa5e"
      },
      "outputs": [],
      "source": [
        "df['sex'] = df['sex'].fillna('unknown')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBpGmLnWIRQA"
      },
      "source": [
        "Kolumnę `age_approx`, która przedstawa przybliżony wiek pacentów, uzupełniamy medianą, gdyż jest to miara odporna na wartości odstające, które mogą być obecne wśród wartości kolumny."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "z-9OT0o7IRyC",
        "outputId": "f6523d12-a2d6-4082-8693-ccdaadd148ae"
      },
      "outputs": [],
      "source": [
        "median_age = df['age_approx'].median()\n",
        "df['age_approx'] = df['age_approx'].fillna(median_age)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgro78a_IWEc"
      },
      "source": [
        "Sprawdźmy, jak wygląda zbiór po uzupełnieniu braków."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqN1KdbBIYKV",
        "outputId": "820f3358-a64d-495c-861d-bd4c84040fae"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0bVES2XIbBb"
      },
      "source": [
        "Przejdźmy teraz do scalenia kolumn ze zmianami skórnymi w jedną kolumnę dla łatwiejszego zarządzania klasami."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gG_jLVWQIdJD",
        "outputId": "7f326eed-20cf-4ae1-953d-49d6db2e4548"
      },
      "outputs": [],
      "source": [
        "lesion_cols = ['MEL', 'NV', 'BCC', 'AK', 'BKL', 'DF', 'VASC', 'SCC', 'UNK']\n",
        "df['typ_zmiany'] = df[lesion_cols].idxmax(axis=1)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzyIRknJIgeG"
      },
      "source": [
        "Usuwamy zbędne kolumny."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "s52MpPPCIihY",
        "outputId": "1771ff2b-efa9-4f42-8915-975b98b3c573"
      },
      "outputs": [],
      "source": [
        "df = df.drop(columns=lesion_cols)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fhl07gUmIklV"
      },
      "source": [
        "Zmienimy teraz nazwy kolumn na polskie odpowiedniki."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rWbLm48mImgH",
        "outputId": "240efa24-1bf8-4bbf-aba2-99bc3faa91e7"
      },
      "outputs": [],
      "source": [
        "columns_pl_dict = {\n",
        "    'image': 'id_zdjecia',\n",
        "    'age_approx': 'wiek',\n",
        "    'anatom_site_general': 'miejsce_zmiany',\n",
        "    'lesion_id': 'id_zmiany',\n",
        "    'sex': 'plec'\n",
        "}\n",
        "\n",
        "df = df.rename(columns=columns_pl_dict)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k09CM445Iz9c"
      },
      "source": [
        "Sprawdźmy teraz poszczególne wartości kolumn `miejsce_zmiany` i `plec`, w celu utworzenia słowników wprowadzających polskie odpowiedniki."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ihJYGUQI0k1",
        "outputId": "cd22599a-c2f1-47c1-a723-0f82011451cb"
      },
      "outputs": [],
      "source": [
        "df['miejsce_zmiany'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KO4siXSmI25B",
        "outputId": "d70cd609-126b-46e8-9883-1d88e2429864"
      },
      "outputs": [],
      "source": [
        "df['plec'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjAYegp5I58Z"
      },
      "source": [
        "Tworzymy słowniki i tłumaczymy wartości."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6PS7l2AI7lf"
      },
      "outputs": [],
      "source": [
        "miejsce_zmiany_dict = {\n",
        "    'anterior torso': 'Przód tułowia',\n",
        "    'upper extremity': 'Kończyna górna',\n",
        "    'lower extremity': 'Kończyna dolna',\n",
        "    'posterior torso': 'Plecy',\n",
        "    'lateral torso': 'Bok tułowia',\n",
        "    'head/neck': 'Głowa/Szyja',\n",
        "    'palms/soles': 'Dłonie/Stopy',\n",
        "    'oral/genital': 'Usta/Narządy płciowe',\n",
        "    'unknown': 'Nieznane'\n",
        "}\n",
        "\n",
        "plec_dict = {\n",
        "    'male': 'Mężczyzna',\n",
        "    'female': 'Kobieta',\n",
        "    'unknown': 'Nie podano'\n",
        "}\n",
        "\n",
        "df['miejsce_zmiany'] = df['miejsce_zmiany'].map(miejsce_zmiany_dict).astype('category')\n",
        "df['plec'] = df['plec'].map(plec_dict).astype('category')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhSmk1LkI91C"
      },
      "source": [
        "Sprawdźmy wyniki."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lY1YAYlII_ul",
        "outputId": "310cb26d-943f-415c-d125-2ba76781fec2"
      },
      "outputs": [],
      "source": [
        "df['miejsce_zmiany'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTIFZrK9JBVl",
        "outputId": "2043c96a-0e14-40a0-a4f4-daaa3f7313e3"
      },
      "outputs": [],
      "source": [
        "df['plec'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GYid2t7JEWR"
      },
      "source": [
        "Podobnie tłumaczymy nazwy wykrytych zmian skórnych."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7ibIhwfJDqM",
        "outputId": "1968aefc-f53b-4d5c-d55c-fba5a7f75a5f"
      },
      "outputs": [],
      "source": [
        "typ_zmiany_dict = {\n",
        "    'MEL': 'Czerniak',                 # Melanoma\n",
        "    'NV': 'Znamię barwnikowe',         # Melanocytic nevus\n",
        "    'BCC': 'Rak podstawnokomórkowy',   # Basal cell carcinoma\n",
        "    'AK': 'Rogowacenie słoneczne',     # Actinic keratosis\n",
        "    'BKL': 'Łagodna zmiana',           # Benign keratosis lesion\n",
        "    'DF': 'Włókniak',                  # Dermatofibroma\n",
        "    'VASC': 'Zmiana naczyniowa',       # Vascular lesion\n",
        "    'SCC': 'Rak kolczystokomórkowy',   # Squamous cell carcinoma\n",
        "    'UNK': 'Nieznana zmiana'           # Unknown\n",
        "}\n",
        "\n",
        "df['typ_zmiany'] = df['typ_zmiany'].map(typ_zmiany_dict).astype('category')\n",
        "df['typ_zmiany'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcvL4KEbJI0e"
      },
      "source": [
        "Zakodujmy teraz zmienną docelową `typ_zmiany` dla późniejszego procesu treningu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "iKBnwumsJLN9",
        "outputId": "12200afb-663e-4ee0-ed3b-fe1c5ebddcff"
      },
      "outputs": [],
      "source": [
        "le = LabelEncoder()\n",
        "df['target'] = le.fit_transform(df['typ_zmiany'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFg-hUfxJNvm"
      },
      "source": [
        "Sprawdźmy jeszcze, jak wygląda kodowanie."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5avunLbfJPdj",
        "outputId": "aaba830e-c916-4079-a605-208c256de127"
      },
      "outputs": [],
      "source": [
        "for i, label in enumerate(le.classes_):\n",
        "    print(f\"Klasa {i} --> {label}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Qsglw_QJRwJ"
      },
      "source": [
        "Zapisujemy obiekt `LabelEncoder` oraz kodowanie do późniejszej pracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0PPGhEDJTc3",
        "outputId": "47ab8b2f-1e35-4f3c-ad05-68e01122015f"
      },
      "outputs": [],
      "source": [
        "# ścieżki\n",
        "encoder_path = os.path.join(DATA_DIR, 'label_encoder.joblib')\n",
        "mapping_path = os.path.join(DATA_DIR, 'mapowanie_klas.json')\n",
        "\n",
        "# zapisanie encodera\n",
        "joblib.dump(le, encoder_path)\n",
        "\n",
        "# wyciągnięcie mapowania i zapisanie JSON\n",
        "class_map_dict = {int(index): label for index, label in enumerate(le.classes_)}\n",
        "\n",
        "with open(mapping_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(class_map_dict, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"Zapisano encoder do: {encoder_path}\")\n",
        "print(f\"Zapisano słownik do: {mapping_path}\")\n",
        "print(\"Podgląd mapowania:\")\n",
        "print(class_map_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gj7o8QyrJZuD"
      },
      "source": [
        "Dodamy teraz kolumnę z nazwą pliku odpowiadającego danej zmianie. Ułatwi to późniejszą pracę."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "KmhwgQQ4JeXY",
        "outputId": "ddd849a6-2ce4-417a-9751-8d0a18c0c264"
      },
      "outputs": [],
      "source": [
        "df['nazwa_pliku'] = df['id_zdjecia'].apply(lambda x: x if x.endswith('.jpg') else f\"{x}.jpg\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlUp40HKJgrw"
      },
      "source": [
        "Sprawdźmy, jak teraz wygląda sytuacja z tabelą."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9KAZw0PJioT",
        "outputId": "d25f0967-82cb-4c06-d20c-af84c0e12f79"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0ovJqPXLx0y"
      },
      "source": [
        "### Rozkład klas w zbiorze"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLGNEma2L173"
      },
      "source": [
        "Zobaczmy teraz, czy klasy w zbiorze są równomiernie rozłożone. Jeśli klasy nie są rozłożene równomiernie, to trzebw wtedy zastosować podział startyfikacyjny, czyli podział, który odwozorwje rozkład klas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "id": "rfMveOWfLzhf",
        "outputId": "5d86c119-91bc-4145-ee5a-e3aa04459ba7"
      },
      "outputs": [],
      "source": [
        "counts = df['typ_zmiany'].value_counts()\n",
        "ax = sns.barplot(x=counts.index,\n",
        "                 y=counts.values,\n",
        "                 palette=\"viridis\",\n",
        "                 hue=counts.index,\n",
        "                 legend=False,\n",
        "                 order=counts.index)\n",
        "\n",
        "plt.title(\"Liczebność klas w zbiorze danych\")\n",
        "plt.ylabel(\"Liczba zdjęć\")\n",
        "plt.xlabel(\"Typ zmiany skórnej\")\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# zapisanie wykresu\n",
        "save_path = os.path.join(RESULTS_DIR, 'rozklad_klas.pdf')\n",
        "plt.savefig(save_path)\n",
        "\n",
        "# wyświetlenie wykresu\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6TlNjMGL7VA"
      },
      "source": [
        "Klasy nie są rozłożone równomiernie, co musimy wziąć pod uwagę podczas podziału."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7wvh6LBMKVj"
      },
      "source": [
        "### Przygotowanie obrazów"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeyUV1aHMRR7"
      },
      "source": [
        "Przejdźmy do analizy obrazów. Sprawdźmy teraz, jakie są wymiary obrazów oraz jakie są systemy kodowania kolorów w zbiorze."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S93JeW0LL7_z",
        "outputId": "fa391dbf-e0dd-4eb6-9eaa-0d73c30290ce"
      },
      "outputs": [],
      "source": [
        "widths = []\n",
        "heights = []\n",
        "modes = [] # zbieranie schematów kodowania kolorów\n",
        "missing_files = 0\n",
        "\n",
        "for filename in tqdm(df['nazwa_pliku'], desc=\"Skanowanie zdjęć\"):\n",
        "    img_path = os.path.join(IMG_DIR, filename)\n",
        "\n",
        "    try:\n",
        "        with Image.open(img_path) as img:\n",
        "            w, h = img.size\n",
        "            widths.append(w)\n",
        "            heights.append(h)\n",
        "            modes.append(img.mode)\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        missing_files += 1\n",
        "    except Exception as e:\n",
        "        print(f\"Błąd przy pliku {filename}: {e}\")\n",
        "\n",
        "# wyznaczanie wartości unikalnych\n",
        "unique_sizes = set(zip(widths, heights))\n",
        "unique_modes = set(modes)\n",
        "\n",
        "print(\"\\nWyniki analizy:\")\n",
        "print(f\"Przeanalizowano plików: {len(widths)}\")\n",
        "if missing_files > 0:\n",
        "    print(f\"Brakujących plików: {missing_files} (Sprawdzić ścieżki!)\")\n",
        "\n",
        "print(f\"1. Unikalne rozmiary: {unique_sizes}\")\n",
        "print(f\"2. Unikalne tryby kolorów: {unique_modes}\")\n",
        "\n",
        "# interpretacja\n",
        "if 'RGB' in unique_modes and len(unique_modes) == 1:\n",
        "    print(\"Wszystkie zdjęcia są w standardzie RGB (3 kanały).\")\n",
        "else:\n",
        "    print(\"UWAGA: Wykryto niestandardowe tryby kolorów!\")\n",
        "    print(f\"   Rozkład trybów: {pd.Series(modes).value_counts().to_dict()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZJTm_KqMWv1"
      },
      "source": [
        "Okazuje się, że wszystkie obrazy są w tym samym systemie kolorów, ale za to mamy różne wymiary zdjęć."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s329E4-lMamn"
      },
      "source": [
        "Zobaczmy przykłady obrazów z naszego zbioru."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ws7OvSSeMXQT",
        "outputId": "c7a98260-4fd4-4024-a36b-8a57482d6711"
      },
      "outputs": [],
      "source": [
        "n_samples = 3\n",
        "classes = df['typ_zmiany'].unique()\n",
        "\n",
        "# tworzymy siatkę wykresów (wiersze = liczba chorób, kolumny = 3 przykłady)\n",
        "fig, axes = plt.subplots(len(classes), n_samples, figsize=(8, 20))\n",
        "\n",
        "for i, lesion in enumerate(classes):\n",
        "    # pobieramy losowe 3 wiersze dla danej choroby\n",
        "    probki = df[df['typ_zmiany'] == lesion].sample(n_samples)\n",
        "\n",
        "    for j, (_, wiersz) in enumerate(probki.iterrows()):\n",
        "        # wczytujemy zdjęcie bezpośrednio\n",
        "        sciezka = os.path.join(IMG_DIR, wiersz['nazwa_pliku'])\n",
        "        img = Image.open(sciezka)\n",
        "        img = img.resize((int(IMG_SIZE * 0.75), int(IMG_SIZE * 0.75)))\n",
        "\n",
        "        # rysujemy\n",
        "        ax = axes[i, j]\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "\n",
        "        # tytuł tylko po lewej stronie\n",
        "        if j == 0:\n",
        "            ax.set_title(lesion, loc='left', fontsize=15)\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# zapisywanie\n",
        "save_path = os.path.join(RESULTS_DIR, 'przyklady_zmian.pdf')\n",
        "plt.savefig(save_path)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfFiQ1Y7Mstw"
      },
      "source": [
        "Zauważmy, że wybrane przykłady zawierają czarną wynietę lub czarne rogi. Spróbujemy się ich częściowo pozbyć, aby trenowane modele lepiej uczyły się zmian skórnych."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Zg9p1hVMuO7"
      },
      "source": [
        "Tworzymy funkcję do wycinania winiety."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgOgWeV9Mtlb"
      },
      "outputs": [],
      "source": [
        "def crop_vignette(image_path, output_path, threshold=20, extra_crop_percent=0.05, min_fill_ratio=0.95):\n",
        "    \"\"\"\n",
        "    Funkcja usuwająca czarne ramki (winiety) z obrazu z dodatkowym marginesem bezpieczeństwa\n",
        "    oraz mechanizmem chroniącym zdjęcia pełnokadrowe.\n",
        "\n",
        "    Parametry:\n",
        "    - image_path: ścieżka do pliku wejściowego.\n",
        "    - output_path: ścieżka zapisu pliku wynikowego.\n",
        "    - threshold: próg jasności (0-255). Piksele ciemniejsze niż ta wartość są traktowane jako tło.\n",
        "    - extra_crop_percent: ułamek (np. 0.05 = 5%), o jaki dodatkowo zmniejszamy ramkę z każdej strony,\n",
        "      aby usunąć postrzępione krawędzie lub pozostałości winiety w rogach.\n",
        "    - min_fill_ratio: współczynnik wypełnienia (zakres 0.0 - 1.0). Określa próg decyzyjny,\n",
        "      czy zdjęcie w ogóle wymaga przycinania. Jeśli wykryty obszar treści zajmuje większą część\n",
        "      zdjęcia niż ta wartość (np. > 95%), algorytm uznaje, że winieta nie występuje (lub jest pomijalna)\n",
        "      i rezygnuje z przycinania, aby nie uszkodzić zmian skórnych dotykających krawędzi.\n",
        "    \"\"\"\n",
        "\n",
        "    # wczytujemy obraz z dysku\n",
        "    img = cv2.imread(image_path)\n",
        "\n",
        "    # jeśli plik jest uszkodzony lub nie istnieje, przerywamy\n",
        "    if img is None:\n",
        "        return False, None\n",
        "\n",
        "    # przekształcamy obraz do skali szarości i wyznaczmy obszar zdjęcia\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    h_img, w_img = gray.shape\n",
        "    total_area = h_img * w_img\n",
        "\n",
        "    # tworzymy maskę binarną:\n",
        "    # - piksele > threshold (treść) dostają wartość 255 (biały)\n",
        "    # - piksele <= threshold (tło/winieta) dostają wartość 0 (czarny)\n",
        "    _, mask = cv2.threshold(gray, threshold, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # znajdujemy położenie treści\n",
        "    # cv2.findNonZero zwraca listę współrzędnych wszystkich białych pikseli na masce\n",
        "    coords = cv2.findNonZero(mask)\n",
        "\n",
        "    # jeśli nie znaleziono żadnych jasnych punktów (zdjęcie jest całe czarne), kończymy\n",
        "    if coords is None:\n",
        "        return False, None\n",
        "\n",
        "    # znajdujemy najmniejszy prostokąt (x, y, szerokość, wysokość), który obejmuje wszystkie jasne punkty\n",
        "    x, y, w, h = cv2.boundingRect(coords)\n",
        "\n",
        "    # obliczamy obszar czystego obrazu oraz współczynnik wypełnienia\n",
        "    rect_area = w * h\n",
        "    fill_ratio = rect_area / total_area\n",
        "\n",
        "    # jeśli treść zajmuje prawie cały obraz (> 95%), to znaczy, że nie ma winiety,\n",
        "    # albo są tylko mikro-paski, których nie warto ruszać, by nie uciąć zmiany\n",
        "    if fill_ratio > min_fill_ratio:\n",
        "        return False, None\n",
        "\n",
        "    # ETAP PRZYCINANIA\n",
        "\n",
        "    # obliczamy ile pikseli uciąć dodatkowo z każdej strony (5% szerokości/wysokości znalezionej ramki)\n",
        "    margin_w = int(w * extra_crop_percent)\n",
        "    margin_h = int(h * extra_crop_percent)\n",
        "\n",
        "    # wyznaczamy nowe współrzędne ramki, zawężając ją do środka:\n",
        "    # przesuwamy początek X w prawo i Y w dół\n",
        "    new_x = x + margin_w\n",
        "    new_y = y + margin_h\n",
        "\n",
        "    # zmniejszamy szerokość i wysokość o marginesy z obu stron (lewo+prawo, góra+dół)\n",
        "    new_w = w - (2 * margin_w)\n",
        "    new_h = h - (2 * margin_h)\n",
        "\n",
        "    # jeśli zdjęcie było bardzo małe lub margines był za duży i \"zjadł\" cały obraz (wymiar <= 0),\n",
        "    # to cofamy się do wersji podstawowej (bez cięcia).\n",
        "    if new_w <= 0 or new_h <= 0:\n",
        "        new_x, new_y, new_w, new_h = x, y, w, h\n",
        "\n",
        "    # sprawdzamy czy przycięcie jest konieczne\n",
        "    # pobieramy oryginalne wymiary obrazu\n",
        "    h_img, w_img = gray.shape\n",
        "\n",
        "    # czy nowa, wyliczona ramka jest mniejsza niż oryginalny obraz?\n",
        "    # jeśli tak, wykonujemy fizyczne cięcie obrazu\n",
        "    if (new_w < w_img) or (new_h < h_img):\n",
        "        # wycinanie fragmentu tablicy\n",
        "        cropped_img = img[new_y:new_y+new_h, new_x:new_x+new_w]\n",
        "\n",
        "        # zapisujemy wynik na dysk\n",
        "        cv2.imwrite(output_path, cropped_img)\n",
        "\n",
        "        # zwracamy sukces oraz informację, ile pikseli ucięto z każdej strony (góra, dół, lewo, prawo)\n",
        "        return True, (new_y, h_img-(new_y+new_h), new_x, w_img-(new_x+new_w))\n",
        "\n",
        "    # jeśli nie trzeba było ciąć (ramka pokrywa się z całym obrazem), zwracamy False\n",
        "    return False, None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iy5iHtosNXEg"
      },
      "source": [
        "Dokonujemy przycięcia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyP7_HN6NYOH",
        "outputId": "bcaad7d0-93cf-4af2-e2b3-2bbbe16de26d"
      },
      "outputs": [],
      "source": [
        "# filtrujemy pliki, biorąc tylko te z rozszerzeniem .jpg lub .png\n",
        "image_files = [f for f in os.listdir(IMG_DIR) if f.lower().endswith(('.jpg', '.png'))]\n",
        "\n",
        "cropped_count = 0\n",
        "copied_count = 0\n",
        "\n",
        "print(f\"Start: {len(image_files)} zdjęć. Dodatkowe cięcie: {EXTRA_CROP*100}%\")\n",
        "\n",
        "# pętla po wszystkich zdjęciach z użyciem paska postępu\n",
        "for f in tqdm(image_files, desc=\"Przetwarzanie\"):\n",
        "\n",
        "    # tworzenie pełnych ścieżek\n",
        "    src_path = os.path.join(IMG_DIR, f)\n",
        "    dst_path = os.path.join(PROCESSED_DIR, f)\n",
        "\n",
        "    # wywołujemy cięcie\n",
        "    is_cropped, _ = crop_vignette(src_path, dst_path, threshold=VIGNETTE_THRESHOLD, extra_crop_percent=EXTRA_CROP, min_fill_ratio=MIN_FILL_RATIO)\n",
        "\n",
        "    if is_cropped:\n",
        "        # jeśli funkcja wykonała cięcie i zapisała plik -> zwiększ licznik\n",
        "        cropped_count += 1\n",
        "    else:\n",
        "        # jeśli funkcja nie przycięła zdjęcia (zwróciła False) -> kopiujemy oryginał bez zmian\n",
        "        shutil.copy(src_path, dst_path)\n",
        "        copied_count += 1\n",
        "\n",
        "print(\"\\nZakończono przycinanie.\")\n",
        "print(f\"Przycięto: {cropped_count}\")\n",
        "print(f\"Skopiowano (bez zmian): {copied_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ov9R0vDcNZRW"
      },
      "source": [
        "Wyświetlmy losowe 5 przykładów, aby zobaczyć efekty przycięcia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zijdAxhVNd-w",
        "outputId": "ed941d95-7cbe-4839-cef1-3f934a7b5908"
      },
      "outputs": [],
      "source": [
        "if not image_files:\n",
        "    print(\"Błąd: Folder wyjściowy jest pusty! Sprawdź, czy skrypt przetwarzający zadziałał poprawnie.\")\n",
        "else:\n",
        "    candidates = []\n",
        "\n",
        "    for f in image_files:\n",
        "        p_orig = os.path.join(IMG_DIR, f)\n",
        "        p_proc = os.path.join(PROCESSED_DIR, f)\n",
        "\n",
        "        # jeśli rozmiar pliku jest inny od oryginalnego, to zapisujemy zdjęcie\n",
        "        if os.path.getsize(p_orig) != os.path.getsize(p_proc):\n",
        "            candidates.append(f)\n",
        "\n",
        "    # losujemy 5 zdjęć do wyświetlenia\n",
        "    samples_pool = candidates if len(candidates) >= 3 else image_files\n",
        "    selected_files = random.sample(samples_pool, min(3, len(samples_pool)))\n",
        "\n",
        "    # WYŚWIETLENIE ZDJĘĆ\n",
        "    # tworzymy siatkę obrazów\n",
        "    fig, axes = plt.subplots(len(selected_files), 2, figsize=(8, 4 * len(selected_files)))\n",
        "\n",
        "    # jeśli mamy tylko 1 zdjęcie, `axes` nie jest tablicą,\n",
        "    # więc zamykamy go w listę, aby pętla for poniżej zadziałała bez błędu.\n",
        "    if len(selected_files) == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    # pętla rysująca\n",
        "    for i, filename in enumerate(selected_files):\n",
        "        path_orig = os.path.join(IMG_DIR, filename)\n",
        "        path_proc = os.path.join(PROCESSED_DIR, filename)\n",
        "\n",
        "        # wczytujemy obrazy\n",
        "        img_orig = Image.open(path_orig)\n",
        "        img_proc = Image.open(path_proc)\n",
        "\n",
        "        # tworzymy kolumnę z oryginalnymi zdjęciami\n",
        "        axes[i, 0].imshow(img_orig)\n",
        "        # wyświetlamy wymiary oryginału w tytule\n",
        "        axes[i, 0].set_title(f\"Oryginał\\n{img_orig.size}\", fontsize=10, color='gray')\n",
        "        axes[i, 0].axis('off') # ukrywamy osie\n",
        "\n",
        "        # tworzymy kolumnę z przyciętymi obrazami\n",
        "        # obliczamy, o ile procent zmniejszyła się powierzchnia zdjęcia.\n",
        "        area_orig = img_orig.width * img_orig.height\n",
        "        area_proc = img_proc.width * img_proc.height\n",
        "        reduction = (1 - (area_proc / area_orig)) * 100\n",
        "\n",
        "        axes[i, 1].imshow(img_proc)\n",
        "\n",
        "        # formatowanie tytułu:\n",
        "        # jeśli redukcja > 0%, to znaczy, że winieta została wycięta -> Kolor ZIELONY + info o %\n",
        "        # jeśli 0%, to zdjęcie było tylko skopiowane -> Kolor CZARNY + \"BEZ ZMIAN\"\n",
        "        if reduction > 0:\n",
        "            title_text = f\"PRZYCIĘTO (Redukcja: {reduction:.1f}%)\\n{img_proc.size}\"\n",
        "            title_col = 'green'\n",
        "        else:\n",
        "            title_text = f\"BEZ ZMIAN\\n{img_proc.size}\"\n",
        "            title_col = 'black'\n",
        "\n",
        "        axes[i, 1].set_title(title_text, fontsize=10, fontweight='bold', color=title_col)\n",
        "        axes[i, 1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # zapisywanie\n",
        "    save_path = os.path.join(RESULTS_DIR, 'przyklady_zmian_przyciete.pdf')\n",
        "    plt.savefig(save_path)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yyQe6-_NkEg"
      },
      "source": [
        "Obraz wyglądają lepiej po przycięciu. Obrazy są zatem przygotowane do dalszej pracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOqriyw5NmGY"
      },
      "source": [
        "## Test klasy `Dataset` i augumentacji danych"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKNje_q5OGSX"
      },
      "source": [
        "Definujemy klasę potomną klasy `Dataset`, która będzie wczytywać poszczególne obrazy zbioru ISIC2019."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V16U_9xBNltA"
      },
      "outputs": [],
      "source": [
        "class ISICDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Niestandardowy Dataset PyTorch do wczytywania obrazów dermatologicznych ISIC.\n",
        "\n",
        "    Klasa wczytuje obrazy na podstawie ścieżek z DataFrame, konwertuje je do RGB\n",
        "    i zwraca w formie gotowej do przetworzenia przez model.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataframe, root_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Inicjalizuje dataset.\n",
        "\n",
        "        Args:\n",
        "            dataframe (pd.DataFrame): Ramka danych zawierająca co najmniej kolumny:\n",
        "                                      - 'nazwa_pliku': nazwa pliku z rozszerzeniem (np. 'IMG_1.jpg')\n",
        "                                      - 'target': numeryczna etykieta klasy (int).\n",
        "            root_dir (str): Ścieżka do katalogu głównego, w którym znajdują się obrazy.\n",
        "            transform (callable, optional): Opcjonalne transformacje (np. augmentacja, normalizacja)\n",
        "                                            aplikowane na obrazie. Domyślnie None.\n",
        "        \"\"\"\n",
        "        self.df = dataframe\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Zwraca całkowitą liczbę próbek w zbiorze.\"\"\"\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Pobiera pojedynczą próbkę danych o podanym indeksie.\n",
        "\n",
        "        Args:\n",
        "            idx (int/tensor): Indeks próbki do pobrania.\n",
        "\n",
        "        Returns:\n",
        "            tuple: Krotka (image, label), gdzie:\n",
        "                   - image (PIL.Image lub Tensor): Obraz po transformacjach.\n",
        "                   - label (int): Numeryczna etykieta klasy.\n",
        "        \"\"\"\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        # pobranie nazwy pliku\n",
        "        img_name = self.df.iloc[idx]['nazwa_pliku']\n",
        "        img_path = os.path.join(self.root_dir, img_name)\n",
        "\n",
        "        # wczytanie obrazu i konwersja na RGB (dla bezpieczeństwa)\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        # pobranie etykiety numerycznej (target)\n",
        "        label = self.df.iloc[idx]['target']\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfSwFJScOVbQ"
      },
      "source": [
        "Definiujemy również transformacje augumentacji na zbiorze treningowym i walidacyjnym."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1L2DaXk1OalX"
      },
      "outputs": [],
      "source": [
        "working_size = int(IMG_SIZE * 1.25)\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    # losujemy wycinek od 80% do 100% powierzchni oryginalnego obrazu\n",
        "    transforms.RandomResizedCrop(working_size, scale=(0.8, 1.0), ratio=(0.9, 1.1)),\n",
        "\n",
        "    # losowe odbicia lustrzane pionowo i poziomo\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "\n",
        "    # delikatna zmiana koloru\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1, hue=0.0),\n",
        "\n",
        "    # obrót zdjęcia o kąt z przedziału (-15 stopni, 15 stopni)\n",
        "    transforms.RandomRotation(15),\n",
        "\n",
        "    # wycinamy środek obrazu w docelowych wymiarach\n",
        "    transforms.CenterCrop(IMG_SIZE),\n",
        "\n",
        "    # przeniesienie na tensor i normalizacja\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(NORM_MEAN, NORM_STD)\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    # zmiana wymiarów\n",
        "    transforms.Resize(working_size),\n",
        "    # wycinamy środek obrazu w docelowych wymiarach\n",
        "    transforms.CenterCrop(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(NORM_MEAN, NORM_STD)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcX325LMOoUu"
      },
      "source": [
        "Spróbujmy zwizualizować jedno zdjęcie w 10 różnych wariantach, aby sprawdzić działanie augumentacji."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yf0ZK_hVO1lX"
      },
      "source": [
        "Dodatkowo zbudujemy funkcję, która odwraca normalizację. Będziemy mogli w ten sposób zobaczyć zmianę w czytelniejszej formie."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1it-fRk0PAQa"
      },
      "outputs": [],
      "source": [
        "def denormalize(tensor, mean, std):\n",
        "    \"\"\"\n",
        "    Cofnięcie procesu normalizacji na tensorze obrazu (przywrócenie oryginalnej skali kolorów).\n",
        "\n",
        "    W uczeniu głębokim obrazy wejściowe są często standaryzowane według wzoru:\n",
        "    $output = (input - mean) / std$. Funkcja ta odwraca tę operację ($output = input * std + mean$),\n",
        "    co jest niezbędne do poprawnej wizualizacji obrazów, które zostały wcześniej\n",
        "    przetworzone przez transformacje PyTorch (np. `transforms.Normalize`).\n",
        "\n",
        "    Args:\n",
        "        tensor (torch.Tensor): Tensor obrazu o kształcie (C, H, W).\n",
        "        mean (tuple/list): Średnie użyte do normalizacji dla każdego kanału (R, G, B).\n",
        "        std (tuple/list): Odchylenia standardowe użyte do normalizacji dla każdego kanału (R, G, B).\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Zdenormalizowany tensor gotowy do konwersji na format obrazu (np. PIL lub NumPy).\n",
        "    \"\"\"\n",
        "    tensor = tensor.clone()\n",
        "    for t, m, s in zip(tensor, mean, std):\n",
        "        t.mul_(s).add_(m)\n",
        "    return tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtiYf_NQOotW",
        "outputId": "5c4fd0b0-ce84-4037-f315-6008f9ddca32"
      },
      "outputs": [],
      "source": [
        "dataset = ISICDataset(df, PROCESSED_DIR, transform=train_transforms)\n",
        "\n",
        "idx = 12345 # indeks zdjęcia do testu augumentacji\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "fig.suptitle(\"Przykład augumentacji danych\", fontsize=20)\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i in range(10):\n",
        "    img_tensor, _ = dataset[idx]\n",
        "    img = denormalize(img_tensor, NORM_MEAN, NORM_STD).permute(1, 2, 0).numpy()\n",
        "    img = np.clip(img, 0, 1)\n",
        "\n",
        "    axes[i].imshow(img)\n",
        "    axes[i].axis('off')\n",
        "\n",
        "# zapisywanie\n",
        "save_path = os.path.join(RESULTS_DIR, 'test_augumentacji.pdf')\n",
        "plt.savefig(save_path)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcCehDPCPLax"
      },
      "source": [
        "Wygląda na to, że transformacje działają poprawnie."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWmOUwi3PNhY"
      },
      "source": [
        "## Test klasy `StratifiedGroupKFold`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekYfenBHPTuz"
      },
      "source": [
        "W procesie treningu będzie korzystać z mechanizmu walidacji krzyżowej z podziałem na pacjenta. Podział ten jest realizowany przez klasę `StratifiedGroupKFold`. Sprawdźmy poprawność tego podziału, czyli sprawdźmy, czy zmiany jednego pacjenta nie pojawiają się różnych podzbiorach. Dodatkowo sprawdzimy, czy klasa poprawnio odwzorowuje rozkład klas w poszczególnych foldach."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2chPjQN-PX_z"
      },
      "source": [
        "Konfigurujemy potrzebne dane."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UB6r1HbUPaJQ"
      },
      "outputs": [],
      "source": [
        "X = df['nazwa_pliku']\n",
        "y = df['target']\n",
        "groups = df['id_zmiany']\n",
        "\n",
        "# inicjalizujemy istancję klasy\n",
        "sgkf = StratifiedGroupKFold(n_splits=CV_FOLDS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWNUNCUHPgLu"
      },
      "source": [
        "Sprawdzamy, czy dochodzi do przecieku danych. Dodatkowo zbierzemy informacje o rozkładzie klas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89b35WeOPlaF",
        "outputId": "64042c47-6c0d-4b8e-fbea-9767b91b3b79"
      },
      "outputs": [],
      "source": [
        "folds_data = [] # do przechowania indeksów\n",
        "fold_stats = [] # do przechowania statystyk procentowych\n",
        "\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(sgkf.split(X, y, groups)):\n",
        "\n",
        "    # tworzymy podzbiory\n",
        "    train_subset = df.iloc[train_idx]\n",
        "    val_subset = df.iloc[val_idx]\n",
        "\n",
        "    # sprawdzamy, czy dochodzi do przecieku danych\n",
        "    # czy istnieją zdjęcia przypisane do obu zbiorów?\n",
        "    train_groups = set(train_subset['id_zmiany'])\n",
        "    val_groups = set(val_subset['id_zmiany'])\n",
        "    overlap = train_groups.intersection(val_groups)\n",
        "    num_overlap = len(overlap)\n",
        "\n",
        "    status = \"OK\" if num_overlap == 0 else \"BŁĄD!\"\n",
        "    print(f\"Fold {fold+1}: Trening={len(train_subset)}, Walidacja={len(val_subset)} | Przeciek: {num_overlap} pacjentów -> {status}\")\n",
        "\n",
        "    # zapisujemy indeksy\n",
        "    folds_data.append((train_idx, val_idx))\n",
        "\n",
        "    # liczymy procentowy udział klas w zbiorze walidacyjnym tego foldu\n",
        "    counts = val_subset['typ_zmiany'].value_counts(normalize=True) * 100\n",
        "    counts.name = f\"Fold {fold+1}\"\n",
        "    fold_stats.append(counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWpPGNPoPtWI"
      },
      "source": [
        "Nie dochodzi do przecieku danych. Do informacji i rozkładzie dodajmy jeszcze rozkład klas w całym zbiorze."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQZ6Nj-3P0_h"
      },
      "outputs": [],
      "source": [
        "global_counts = df['typ_zmiany'].value_counts(normalize=True) * 100\n",
        "global_counts.name = 'Cały zbiór'\n",
        "fold_stats.append(global_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GuVL02xP3U-"
      },
      "source": [
        "Zbudujmy ramkę danych i posortujmy kolumny po częsitości występowania w całym zbiorze."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "knZNB-GdP75P",
        "outputId": "50b9a995-5401-49fb-ebab-2fa21772a2df"
      },
      "outputs": [],
      "source": [
        "dist_df = pd.DataFrame(fold_stats)\n",
        "\n",
        "# sortujemy kolumny od najczęstszej do najrzadszej względem wiersza rozkładu całego zbioru\n",
        "sorted_columns = dist_df.loc['Cały zbiór'].sort_values(ascending=False).index\n",
        "dist_df = dist_df[sorted_columns]\n",
        "\n",
        "dist_df.round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Or0eNpsP_-n"
      },
      "source": [
        "Zwizualizujemy odwzorowanie klas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "id": "pbbUsF9pP_Yn",
        "outputId": "cfd55cc6-3fe4-45bf-90c8-38008c47fdb2"
      },
      "outputs": [],
      "source": [
        "ax = dist_df.plot(kind='bar', stacked=True, colormap='viridis', width=0.8)\n",
        "\n",
        "plt.title(\"Rozkład klas w foldach w porównaniu z całym zbiorem\")\n",
        "plt.xlabel(\"Zbiór danych\")\n",
        "plt.ylabel(\"Udział procentowy (%)\")\n",
        "plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', title=\"Typ zmiany\")\n",
        "plt.xticks(rotation=45)\n",
        "# plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "\n",
        "# zapisywanie\n",
        "save_path = os.path.join(RESULTS_DIR, 'rozklad_klas_foldy.pdf')\n",
        "plt.savefig(save_path)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOnxaB8eQHDQ"
      },
      "source": [
        "Możemy zatem stwierdzić, że klasa działa tak, jak tego oczekiwaliśmy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agvarMnOQUhx"
      },
      "source": [
        "## Test klasy `DataLoader`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmvNvp2DQbGH"
      },
      "source": [
        "Przejdźmy do przetestowania obiektu `DataLoader` (klasy wprowadzającej dane do modelu w procesie uczenia). Sprawdzimy, czy wszystko będzie wykonywane poprawnie na jednym z podzbiorów podziału."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azFbJwQEQkoq"
      },
      "source": [
        "Tworzymy zbiór danych z jednego folda podziału."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3l60A9RQhns",
        "outputId": "736c036a-68a4-4980-b5b2-2c96147f4d80"
      },
      "outputs": [],
      "source": [
        "# pobieramy indeksy dla pierwszego foldu z generatora\n",
        "train_idx, val_idx = next(sgkf.split(X, y, groups))\n",
        "\n",
        "# tworzymy podzbiory\n",
        "train_df = df.iloc[train_idx].reset_index(drop=True)\n",
        "val_df = df.iloc[val_idx].reset_index(drop=True)\n",
        "\n",
        "print(f\"Podział danych:\")\n",
        "print(f\" -> Trening: {len(train_df)} zdjęć\")\n",
        "print(f\" -> Walidacja: {len(val_df)} zdjęć\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KQu0DQrQ1ub"
      },
      "source": [
        "Inicjalizujemy instancje `ISICDataset` na przygotowanych zbiorach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amzLglofQ2hg"
      },
      "outputs": [],
      "source": [
        "train_dataset = ISICDataset(train_df, PROCESSED_DIR, transform=train_transforms)\n",
        "val_dataset = ISICDataset(val_df, PROCESSED_DIR, transform=val_transforms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coqbl3HMQ6hu"
      },
      "source": [
        "Tworzymy instancje klasy `DataLoader` dla zbioru treningowego i testowego."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gp0rR6r_Q7ij",
        "outputId": "a6fef58c-d23e-4bd8-e2b8-7c42b91bf74f"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,          # mieszamy dane treningowe\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True,       # przyspiesza transfer do GPU\n",
        "    drop_last=True         # odrzucamy ostatnią niepełną partię\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,         # w walidacji nie mieszamy\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "print(f\"Liczba partii w epoce (trening): {len(train_loader)}\")\n",
        "print(f\"Liczba partii w epoce (walidacja): {len(val_loader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AubkBy4Q-34"
      },
      "source": [
        "Zbieramy informacji o jednej partii."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_3-vwZ_Q_Zv",
        "outputId": "34152816-df80-4089-b357-06f2a63caf49"
      },
      "outputs": [],
      "source": [
        "images, labels = next(iter(train_loader))\n",
        "\n",
        "print(f\"Analiza pobranej partii:\")\n",
        "print(f\" -> Kształt obrazów: {images.shape}  (liczność partii, C, H, W)\")\n",
        "print(f\" -> Kształt etykiet: {labels.shape}\")\n",
        "print(f\" -> Przykładowe etykiety: {labels[:10].tolist()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTEWwuTJRXzG"
      },
      "source": [
        "Wygląda na to, że instancje `DataLoader` działają poprawnie. Zobaczmy jeszcze, jak wygląda partia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 631
        },
        "id": "0efsHPdGRIOe",
        "outputId": "e3bc52ee-c0d3-42a1-c291-44f7b49f9526"
      },
      "outputs": [],
      "source": [
        "# tworzymy siatkę\n",
        "grid_img = make_grid(images[:BATCH_SIZE], nrow=8, padding=2, normalize=False)\n",
        "\n",
        "# przenosimy na cpu i zmieniamy kolejność wymiarów (C, H, W) -> (H, W, C)\n",
        "grid_img = grid_img.permute(1, 2, 0).cpu().numpy()\n",
        "\n",
        "# odwracamy normalizację\n",
        "grid_img = grid_img * NORM_STD + NORM_MEAN\n",
        "\n",
        "# sprowadzamy zakers do  [0,1]\n",
        "grid_img = np.clip(grid_img, 0, 1)\n",
        "\n",
        "# tworzymy wykres\n",
        "plt.imshow(grid_img)\n",
        "plt.title(f\"Przykładowa partia danych treningowych\")\n",
        "plt.axis('off')\n",
        "\n",
        "# zapisujemy\n",
        "save_path = os.path.join(RESULTS_DIR, 'przyklad_partii.pdf')\n",
        "plt.savefig(save_path)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2gQQcXGRLB5"
      },
      "source": [
        "Możemy zatem przejść do podzielenia danych do dalszych etapów projektu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tx7Zbl-ORmJJ"
      },
      "source": [
        "## Ostateczny podział danych do trenowania modeli"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aLHzyjnR_A8"
      },
      "source": [
        "Przy podziale danych oddzielimy 10% zbioru na zbiór testowy, a pozostałe 90% podzielimy na zbiór treningowy i walidacyjny. Wszystko przy pomocy `StratifiedGroupKFold`, aby uzyskać podział na poziomie pacjenta/zmiany. Instrukcje podziały (numery foldów dla każdej obserwacji) zapiszemy w tabeli z metadanymi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3KhWWF8Skq0"
      },
      "source": [
        "Tworzymy końcową ramkę metadanych i inicjalizujemy w niej kolumny przypisujące numer foldu danej obserwacji."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "nODBRIjBSlue",
        "outputId": "38355542-f0af-4f30-b2aa-d269f6cbc428"
      },
      "outputs": [],
      "source": [
        "df_final = df.reset_index(drop=True)\n",
        "\n",
        "df_final['typ_puli'] = 'trening'  # domyślnie wszystko trafia do puli treningowej\n",
        "df_final['nr_podzbioru'] = -1     # -1 oznacza zbiór testowy\n",
        "\n",
        "df_final.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8muPVrvSq_x"
      },
      "source": [
        "Dokonujemy wydzielenia zbioru testowego."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "V9xHWfQNSuE7",
        "outputId": "c0755f0f-69c9-4662-bcf5-13a8b6c0ad4c"
      },
      "outputs": [],
      "source": [
        "test_splitter = StratifiedGroupKFold(n_splits=TEST_SPLIT)\n",
        "\n",
        "# generujemy indeksy podziału\n",
        "generator = test_splitter.split(df_final, y, groups)\n",
        "\n",
        "# pobieramy indeksy pierwszego podziału\n",
        "train_idx, test_idx = next(generator)\n",
        "\n",
        "# przypisujemy wybranym ideksom kategorie zbioru testowego\n",
        "df_final.loc[test_idx, 'typ_puli'] = 'test'\n",
        "\n",
        "df_final.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kw4s3el9Szuv"
      },
      "source": [
        "Dzielimy resztę na zbiór treningowy i walidacyjny w poszczególnych foldach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rvaW5WGKS2JG",
        "outputId": "174d8f1d-de7f-4f0d-92af-9adbe4f3e583"
      },
      "outputs": [],
      "source": [
        "# tworzymy tymczasowy widok tylko na dane treningowe\n",
        "train_mask = df_final['typ_puli'] == 'trening'\n",
        "df_train_temp = df_final[train_mask].reset_index(drop=True)\n",
        "\n",
        "cv_splitter = StratifiedGroupKFold(n_splits=CV_FOLDS)\n",
        "\n",
        "# dzielimy df_train_temp na foldy\n",
        "for fold_num, (t_idx, v_idx) in enumerate(cv_splitter.split(df_train_temp, df_train_temp['target'], df_train_temp['id_zmiany'])):\n",
        "\n",
        "    # pobieramy ID zmian, które trafiły do walidacji w tym foldzie\n",
        "    val_lesion_ids = df_train_temp.loc[v_idx, 'id_zmiany'].values\n",
        "\n",
        "    # przenosimy tę informację do głównej tabeli\n",
        "    # przypisujemy numer foldu walidacyjnego tym wierszom, które są w puli treningowej\n",
        "    # i są w zbiorze walidacyjnym powyższego odziału\n",
        "    condition = (df_final['typ_puli'] == 'trening') & (df_final['id_zmiany'].isin(val_lesion_ids))\n",
        "    df_final.loc[condition, 'nr_podzbioru'] = fold_num\n",
        "\n",
        "df_final.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYqigrULS4y8"
      },
      "source": [
        "Sprawdźmy liczbę obserwacji w każdym z podzbiorów."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "h738iykDS9yx",
        "outputId": "8ac9fe49-f476-4667-a10b-181498f28bd1"
      },
      "outputs": [],
      "source": [
        "df_final.groupby(['typ_puli', 'nr_podzbioru']).size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrZvY0jSTAoS"
      },
      "source": [
        "Sprawdźmy teraz, czy po takim podziale został poprawnie odwzorowany rozkład klas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyYUjO8JTC8n"
      },
      "outputs": [],
      "source": [
        "# obliczamy rozkład klas dla zbioru testowego\n",
        "test_counts = df_final[df_final['typ_puli'] == 'test']['typ_zmiany'].value_counts(normalize=True) * 100\n",
        "\n",
        "# obliczamy rozkład dla każdego foldu\n",
        "fold_counts = {}\n",
        "for i in range(CV_FOLDS):\n",
        "    # wybieramy wiersze należące do konkretnego foldu\n",
        "    fold_subset = df_final[df_final['nr_podzbioru'] == i]\n",
        "    fold_counts[f'Fold {i}'] = fold_subset['typ_zmiany'].value_counts(normalize=True) * 100\n",
        "\n",
        "# łączymy wszystko w jedną ramkę danych\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Cały zbiór': global_counts,\n",
        "    'Zbiór testowy': test_counts,\n",
        "    **fold_counts # rozpakowujemy słownik z foldami\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIUPoQsCTFGn"
      },
      "source": [
        "Zobaczmy rozkład klas w podziale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "yuyCdY5BTH5l",
        "outputId": "70578eb2-2888-4ae0-ada8-236bafce7280"
      },
      "outputs": [],
      "source": [
        "comparison_df = comparison_df.sort_values(by='Cały zbiór', ascending=False)\n",
        "\n",
        "comparison_df.round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kb5A2rvYTwF9"
      },
      "source": [
        "Upewnijmy się, że nie ma zbyt dużych odchyleń w rozkładach klas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDoR-2IzTx3N",
        "outputId": "87a22fa0-4370-4416-dc24-8d93b0489eda"
      },
      "outputs": [],
      "source": [
        "# szukamy maksymalnego odchylenia\n",
        "# odejmujemy od każdej kolumny wartość dla całego zbioru i szukamy maksymalnej różnicy\n",
        "diff_df = comparison_df.subtract(comparison_df['Cały zbiór'], axis=0).abs()\n",
        "max_diff = diff_df.max().max()\n",
        "\n",
        "print(f\"Maksymalne odchylenie od średniej globalnej: {max_diff:.2f} punktu procentowego.\")\n",
        "if max_diff < 1.5:\n",
        "    print(\"Podział jest bardzo dobrze zbalansowany.\")\n",
        "else:\n",
        "    print(\"Uwaga: Istnieją pewne dysproporcje w podziale.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r__tMS56T0NA"
      },
      "source": [
        "Zapisujemy ostatecznie przetworzone metadane."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWFaQrwFT1w4",
        "outputId": "456f62c1-1b7e-4f8a-a693-d0c28f5d5b3a"
      },
      "outputs": [],
      "source": [
        "save_path = os.path.join(DATA_DIR, 'ISIC_metadata_processed.csv')\n",
        "df_final.to_csv(save_path, index=False)\n",
        "print(f\"Zapisano metadae do: {save_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtxFjkvqUWHp"
      },
      "source": [
        "Dokonaliśmy zatem ostatecznego podziału danych do treningu. Zapisaliśmy wszelkie metadane potrzebne w kolejnych etapach projekty. Wszlekie elementy potoku pracy (podział danych, klasy `Dataset` i `DataLoader`) działają poprawnie."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0TQsBt3lbz5"
      },
      "source": [
        "# Diagnostyka raka skóry z wykorzystaniem analizy obrazów dermatologicznych - trening DenseNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdUHDAw1ldoW"
      },
      "source": [
        "Celem tego notatnika jest wczytanie wstępnie wytrenowanego modelu DenseNet-121 i dostrojenie go na zbiorze ISIC2019 w celu klasyfikowania obrazu ze zmianą skórnej do jednej z klas. Do tego zadania wykorzystamy wszelkie implementacje i pliki, które wykorzystaliśmy w notatniku `01_przygotowanie_danych.ipynb`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsgcgpJymC7s"
      },
      "source": [
        "## Konfiguracja środowiska"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbkKOutTmCL_"
      },
      "source": [
        "Importujemy potrzebne biblioteki."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MjIi5I3lLlf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive, files\n",
        "import kagglehub\n",
        "import random\n",
        "import time\n",
        "import copy\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from sklearn.metrics import matthews_corrcoef, accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import multiprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7240iclmpoE"
      },
      "source": [
        "Definiujemy zmienne globalne."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rf8_H0Komqs7"
      },
      "outputs": [],
      "source": [
        "# parametry globalne\n",
        "SEED = 42\n",
        "BATCH_SIZE = 64                                                         # wielkość partii danych\n",
        "NUM_WORKERS = min(4, multiprocessing.cpu_count())                       # liczba wątków procesora\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "MODEL_NAME = 'DenseNet-121'                                             # nazwa modelu\n",
        "NUM_CLASSES = 8                                                         # liczba klas\n",
        "\n",
        "# parametry transformacji obrazów\n",
        "IMG_SIZE = 300                      # wymiar wejściowy obrazu\n",
        "NORM_MEAN = [0.485, 0.456, 0.406]   # wartości średniej do normalizacji\n",
        "NORM_STD = [0.229, 0.224, 0.225]    # wartości odchyleń do normalizacji\n",
        "\n",
        "# parametry czyszczenia danych\n",
        "VIGNETTE_THRESHOLD = 20      # próg czerni\n",
        "EXTRA_CROP = 0.05            # margines dodatkowego przycięcia (5%)\n",
        "MIN_FILL_RATIO = 0.95        # bezpiecznik dla zdjęć pełnokadrowych\n",
        "\n",
        "# podział danych\n",
        "CV_FOLDS = 5                 # liczba foldów walidacyjnych\n",
        "\n",
        "# hiperparametry treningu w pierwszym etapie\n",
        "WARMUP_EPOCHS = 10           # liczba epok (mała)\n",
        "WARMUP_LR = 1e-3            # wartość współczynnika uczenia (duża)\n",
        "WARMUP_PATIENCE = 5         # cierpliość na poprawę modelu (mała)\n",
        "\n",
        "# hiperparametry treningu w drugim etapie\n",
        "FINETUNE_EPOCHS = 60      # licza epok (duża)\n",
        "FINETUNE_LR = 3e-5        # wartość współczynnika uczenia (mała)\n",
        "FINETUNE_PATIENCE = 12    # cierpliwość na poprawę modelu (duża)\n",
        "\n",
        "WEIGHT_DECAY = 1e-2      # wielkość kary za duże wartości wag"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b15AvFa7pZX_"
      },
      "source": [
        "Aby móc uzyskać dostęp do GPU w notatniku należy wybrać:\n",
        "\n",
        "$\\textbf{Środowisko wykonawcze} ⟶ \\textbf{Zmień typ środowiska wykonwaczego} ⟶ \\text{Wybieramy jedno z dostępnych GPU} ⟶ \\textbf{Zapisz}$\n",
        "\n",
        "Po takiej sekwencji operacji należy przepuścić kod notatnika od samego początku, gdyż zostanie przydzielona nowa sesja, a poprzednia zostanie usunięta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUNFlUKaozS-"
      },
      "source": [
        "Ustawiamy ziarno losości dla powtarzalności wyników."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZ7DSdgAmx6O"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed=42):\n",
        "    \"\"\"Ustawia ziarno losowości dla reprodukowalności wyników.\"\"\"\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEH2TAe5m1gK"
      },
      "outputs": [],
      "source": [
        "set_seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeQYKLg8ngCk"
      },
      "source": [
        "Dodatkowo konfigurujemy wygląd wykresów w całym notatniku."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H47rVhTwnNY0"
      },
      "outputs": [],
      "source": [
        "# bazowy styl seaborn z siatką\n",
        "sns.set_theme(style=\"whitegrid\", context=\"notebook\", font_scale=1.1)\n",
        "\n",
        "# ustawienia matplotlib\n",
        "plt.rcParams.update({\n",
        "    'figure.figsize': (10, 6),       # domyślny rozmiar wykresu\n",
        "    'figure.dpi': 120,               # wyraźny wygląd wykresów w Colabie\n",
        "    'savefig.dpi': 300,              # wysoka rozdzielczość zapisywanych wykresów\n",
        "    'savefig.bbox': 'tight',         # automatycznie przycinanie białych marginesów przy zapisie\n",
        "    'font.family': 'sans-serif',     # wykorzystanie czcionki bezszerfyowej\n",
        "    'font.sans-serif': ['DejaVu Sans', 'Arial'],\n",
        "    'axes.spines.top': False,        # usuwanie górnej ramki\n",
        "    'axes.spines.right': False,      # usuwanie prawej ramki\n",
        "})\n",
        "\n",
        "# wyostrzone grafiki w Colabie\n",
        "%config InlineBackend.figure_format = 'retina'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCE_6tQdnWCC"
      },
      "source": [
        "Konfigurujemy wszelki potrzebne ścieżki."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsSXxtBEnSGt",
        "outputId": "3bf559ee-4efb-4f11-eca2-e8a9074144ed"
      },
      "outputs": [],
      "source": [
        "# montowanie Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# podajemy nazwę głównego folderu projektu\n",
        "PROJECT_FOLDER_NAME = 'Implementacja'\n",
        "BASE_DIR = os.path.join('/content/drive/MyDrive/Diagnostyka raka skóry z wykorzystaniem analizy obrazów dermatologicznych', PROJECT_FOLDER_NAME)\n",
        "\n",
        "# podajemy ścieżkę w Colabie do zapisania pobieranych danych\n",
        "DATA_ROOT_DIR = '/content/ISIC2019'\n",
        "IMG_DIR = os.path.join(DATA_ROOT_DIR, 'images')\n",
        "PROCESSED_DIR = os.path.join(DATA_ROOT_DIR, 'images_processed')\n",
        "\n",
        "# definijemy podfoldery\n",
        "MODELS_DIR = os.path.join(BASE_DIR, 'Modele')\n",
        "RESULTS_DIR = os.path.join(BASE_DIR, 'Wyniki')\n",
        "DATA_DIR = os.path.join(BASE_DIR, 'Dane')\n",
        "\n",
        "# tworzymy foldery na Google Drive (jeśli nie istnieją)\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Katalog roboczy projektu: {BASE_DIR}\")\n",
        "print(f\"Dane będą zapisywane w: {DATA_ROOT_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgXx9vUAqi60"
      },
      "source": [
        "### Konfiguracja Kaggle API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wM2KUbFYqnux"
      },
      "source": [
        "Kaggle API jest nam potrzebne do pobrania danych bezpośrednio do notatnika. Folder ZIP jest bardzo obszernym plikiem i ręczne wgrywanie go na Google Drive może zająć bardzo dużo czasu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGoUpwx0qrBe"
      },
      "source": [
        "Kofigurujemy ścieżkę dla Kaggle API. Klucz będzie zapisywany bezpośrednio w folderze projektu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbbqiOlWqnL3"
      },
      "outputs": [],
      "source": [
        "kaggle_key_drive_path = os.path.join(BASE_DIR, 'kaggle.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOCgiZE9quBn"
      },
      "source": [
        "Tworzymy w Colabie folder na plik z Kaggle API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBjTXnWLqzCS"
      },
      "outputs": [],
      "source": [
        "kaggle_sys_dir = '/root/.kaggle'\n",
        "os.makedirs(kaggle_sys_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j--omgM5q2E7"
      },
      "source": [
        "Wprowadzamy Kaggle API. Klucz ten należy utworzyć indywidualnie dla każdego użytkownika notatników z implementacją pracy inżynierskie. Aby go zdobyć należy:\n",
        "1. Zalogować się na swój profil na stronie Kaggle.\n",
        "2. Wejście w ustawienia swojego profilu (kilkamy na swoje zdjęcie profilowe i wybieramy ,,Settings'').\n",
        "3. W sekcji ,,API'' klikamy ,,Generate New Token'', następnie wprowadzamy nazwę tokenu i klikamy ,,Generate''.\n",
        "4. Kopiujemy kod z okienka ,,API TOKEN''.\n",
        "5. W dowolnym edytorze tekstu (np. Notatniku) wprowadzamy tekst o następującej strykturze\n",
        "$$\\{\\text{\"username\":\"nazwa_uzytkownika_kaggle\",\"key\":\"skopiowane_kaggle_api\"}\\}$$\n",
        "i zapisujemy plik jako ,,kaggle.json''.\n",
        "W poniższej funkcji zostaniemy poproszeni o wgranie utworzonego pliku.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ES-9ecIIq1Zo"
      },
      "outputs": [],
      "source": [
        "# sprawdzamy czy klucz jest już na Drive\n",
        "if not os.path.exists(kaggle_key_drive_path):\n",
        "    print(f\"UWAGA: Nie znaleziono pliku kaggle.json w lokalizacji: {kaggle_key_drive_path}\")\n",
        "    print(\"Proszę przesłać plik kaggle.json teraz (zostanie zapisany na Drive):\")\n",
        "\n",
        "    # przesyłamy plik kaggle.json\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for filename in uploaded.keys():\n",
        "        if filename == 'kaggle.json':\n",
        "            # zapisujemy trwale na Google Drive\n",
        "            with open(kaggle_key_drive_path, 'wb') as f:\n",
        "                f.write(uploaded[filename])\n",
        "            print(f\"Zapisano kaggle.json w: {kaggle_key_drive_path}\")\n",
        "        else:\n",
        "            print(f\"Pominięto plik: {filename} (oczekiwano kaggle.json)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FIaotoDq_-W"
      },
      "source": [
        "## Pobranie danych"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYeaiqFkrDvT"
      },
      "source": [
        "Pobieramy, rozpakowujemy i porządkujemy zbiór ISIC2019. Nie pobieramy obrazów na dysk Google Drive, lecz do pamięci Google Colab. Pozwoli to na sprawniejsze wczytywanie plików w notatniku."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S66P1SGNrEKY",
        "outputId": "2db74995-92d9-4243-a2b1-994958af66e3"
      },
      "outputs": [],
      "source": [
        "if os.path.exists(kaggle_key_drive_path):\n",
        "    # instalacja klucza w systemie\n",
        "    shutil.copy(kaggle_key_drive_path, os.path.join(kaggle_sys_dir, 'kaggle.json'))\n",
        "    os.chmod(os.path.join(kaggle_sys_dir, 'kaggle.json'), 600)\n",
        "    print(\"Klucz Kaggle API skonfigurowany.\")\n",
        "\n",
        "    # POBIERANIE I PORZĄDKOWANIE DANYCH\n",
        "\n",
        "    # sprawdzamy, czy folder ze zdjęciami już istnieje i jest pełny\n",
        "    # (np. czy nie uruchamiamy komórki drugi raz w tej samej sesji)\n",
        "    if not os.path.exists(IMG_DIR):\n",
        "        print(\"\\nPobieranie danych z Kaggle...\")\n",
        "        # pobieramy do folderu tymczasowego\n",
        "        path = kagglehub.dataset_download(\"andrewmvd/isic-2019\")\n",
        "        print(f\"Pobrano dane do folderu tymczasowego: {path}\")\n",
        "\n",
        "        # tworzymy docelowe foldery na obrazy\n",
        "        os.makedirs(IMG_DIR, exist_ok=True)\n",
        "        os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
        "\n",
        "        # przenosimy metadane w folderu z danymi w Colabie\n",
        "        for csv_file in glob.glob(os.path.join(path, \"*.csv\")):\n",
        "            shutil.copy(csv_file, DATA_ROOT_DIR)\n",
        "            print(f\"Przeniesiono: {os.path.basename(csv_file)}\")\n",
        "\n",
        "        # szukamy rekursywnie zdjęć we wszystkich podfolderach pobranych danych\n",
        "        jpg_files = glob.glob(os.path.join(path, \"**\", \"*.jpg\"), recursive=True)\n",
        "\n",
        "        print(f\"Znaleziono {len(jpg_files)} zdjęć.\")\n",
        "\n",
        "        for file_path in tqdm(jpg_files, desc=\"Kopiowanie zdjęć\", unit=\"plik\"):\n",
        "            # przenosimy plik do wspólnego folderu\n",
        "            shutil.copy(file_path, os.path.join(IMG_DIR, os.path.basename(file_path)))\n",
        "        print(\"Przeniesiono zdjęcia do folderu z danymi.\")\n",
        "\n",
        "        # weryfikujemy liczbę plików\n",
        "        num_images = len(os.listdir(IMG_DIR))\n",
        "        print(f\"\\nSUKCES: Dane gotowe w {DATA_ROOT_DIR}\")\n",
        "        print(f\"Liczba zdjęć w {IMG_DIR}: {num_images}\")\n",
        "\n",
        "    else:\n",
        "        print(\"Dane są już pobrane i uporządkowane.\")\n",
        "        print(f\"Lokalizacja zdjęć: {IMG_DIR}\")\n",
        "\n",
        "else:\n",
        "    print(\"BŁĄD: Brak pliku kaggle.json. Nie można pobrać danych.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jL9umsGPrSyU"
      },
      "source": [
        "## Przygotowanie danych do treningu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCwgLOgprZOk"
      },
      "source": [
        "Wczytujemy metadane."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "90QoW0U7rXhx",
        "outputId": "54a6d877-67f9-4600-9e45-9dcc53b5ed89"
      },
      "outputs": [],
      "source": [
        "metadata_processed_path = os.path.join(DATA_DIR, 'ISIC_metadata_processed.csv')\n",
        "df = pd.read_csv(metadata_processed_path)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZfyyV9wrut4"
      },
      "source": [
        "Wczytujemy i przycinamy zdjęcia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pg_rPkTbrzz6"
      },
      "outputs": [],
      "source": [
        "def crop_vignette(image_path, output_path, threshold=20, extra_crop_percent=0.05, min_fill_ratio=0.95):\n",
        "    \"\"\"\n",
        "    Funkcja usuwająca czarne ramki (winiety) z obrazu z dodatkowym marginesem bezpieczeństwa\n",
        "    oraz mechanizmem chroniącym zdjęcia pełnokadrowe.\n",
        "\n",
        "    Parametry:\n",
        "    - image_path: ścieżka do pliku wejściowego.\n",
        "    - output_path: ścieżka zapisu pliku wynikowego.\n",
        "    - threshold: próg jasności (0-255). Piksele ciemniejsze niż ta wartość są traktowane jako tło.\n",
        "    - extra_crop_percent: ułamek (np. 0.05 = 5%), o jaki dodatkowo zmniejszamy ramkę z każdej strony,\n",
        "      aby usunąć postrzępione krawędzie lub pozostałości winiety w rogach.\n",
        "    - min_fill_ratio: współczynnik wypełnienia (zakres 0.0 - 1.0). Określa próg decyzyjny,\n",
        "      czy zdjęcie w ogóle wymaga przycinania. Jeśli wykryty obszar treści zajmuje większą część\n",
        "      zdjęcia niż ta wartość (np. > 95%), algorytm uznaje, że winieta nie występuje (lub jest pomijalna)\n",
        "      i rezygnuje z przycinania, aby nie uszkodzić zmian skórnych dotykających krawędzi.\n",
        "    \"\"\"\n",
        "\n",
        "    # wczytujemy obraz z dysku\n",
        "    img = cv2.imread(image_path)\n",
        "\n",
        "    # jeśli plik jest uszkodzony lub nie istnieje, przerywamy\n",
        "    if img is None:\n",
        "        return False, None\n",
        "\n",
        "    # przekształcamy obraz do skali szarości i wyznaczmy obszar zdjęcia\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    h_img, w_img = gray.shape\n",
        "    total_area = h_img * w_img\n",
        "\n",
        "    # tworzymy maskę binarną:\n",
        "    # - piksele > threshold (treść) dostają wartość 255 (biały)\n",
        "    # - piksele <= threshold (tło/winieta) dostają wartość 0 (czarny)\n",
        "    _, mask = cv2.threshold(gray, threshold, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # znajdujemy położenie treści\n",
        "    # cv2.findNonZero zwraca listę współrzędnych wszystkich białych pikseli na masce\n",
        "    coords = cv2.findNonZero(mask)\n",
        "\n",
        "    # jeśli nie znaleziono żadnych jasnych punktów (zdjęcie jest całe czarne), kończymy\n",
        "    if coords is None:\n",
        "        return False, None\n",
        "\n",
        "    # znajdujemy najmniejszy prostokąt (x, y, szerokość, wysokość), który obejmuje wszystkie jasne punkty\n",
        "    x, y, w, h = cv2.boundingRect(coords)\n",
        "\n",
        "    # obliczamy obszar czystego obrazu oraz współczynnik wypełnienia\n",
        "    rect_area = w * h\n",
        "    fill_ratio = rect_area / total_area\n",
        "\n",
        "    # jeśli treść zajmuje prawie cały obraz (> 95%), to znaczy, że nie ma winiety,\n",
        "    # albo są tylko mikro-paski, których nie warto ruszać, by nie uciąć zmiany\n",
        "    if fill_ratio > min_fill_ratio:\n",
        "        return False, None\n",
        "\n",
        "    # ETAP PRZYCINANIA\n",
        "\n",
        "    # obliczamy ile pikseli uciąć dodatkowo z każdej strony (5% szerokości/wysokości znalezionej ramki)\n",
        "    margin_w = int(w * extra_crop_percent)\n",
        "    margin_h = int(h * extra_crop_percent)\n",
        "\n",
        "    # wyznaczamy nowe współrzędne ramki, zawężając ją do środka:\n",
        "    # przesuwamy początek X w prawo i Y w dół\n",
        "    new_x = x + margin_w\n",
        "    new_y = y + margin_h\n",
        "\n",
        "    # zmniejszamy szerokość i wysokość o marginesy z obu stron (lewo+prawo, góra+dół)\n",
        "    new_w = w - (2 * margin_w)\n",
        "    new_h = h - (2 * margin_h)\n",
        "\n",
        "    # jeśli zdjęcie było bardzo małe lub margines był za duży i \"zjadł\" cały obraz (wymiar <= 0),\n",
        "    # to cofamy się do wersji podstawowej (bez cięcia).\n",
        "    if new_w <= 0 or new_h <= 0:\n",
        "        new_x, new_y, new_w, new_h = x, y, w, h\n",
        "\n",
        "    # sprawdzamy czy przycięcie jest konieczne\n",
        "    # pobieramy oryginalne wymiary obrazu\n",
        "    h_img, w_img = gray.shape\n",
        "\n",
        "    # czy nowa, wyliczona ramka jest mniejsza niż oryginalny obraz?\n",
        "    # jeśli tak, wykonujemy fizyczne cięcie obrazu\n",
        "    if (new_w < w_img) or (new_h < h_img):\n",
        "        # wycinanie fragmentu tablicy\n",
        "        cropped_img = img[new_y:new_y+new_h, new_x:new_x+new_w]\n",
        "\n",
        "        # zapisujemy wynik na dysk\n",
        "        cv2.imwrite(output_path, cropped_img)\n",
        "\n",
        "        # zwracamy sukces oraz informację, ile pikseli ucięto z każdej strony (góra, dół, lewo, prawo)\n",
        "        return True, (new_y, h_img-(new_y+new_h), new_x, w_img-(new_x+new_w))\n",
        "\n",
        "    # jeśli nie trzeba było ciąć (ramka pokrywa się z całym obrazem), zwracamy False\n",
        "    return False, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRAQuDLvr9AJ",
        "outputId": "16ece37f-9e4a-416b-aaee-12ab73bc8b77"
      },
      "outputs": [],
      "source": [
        "# filtrujemy pliki, biorąc tylko te z rozszerzeniem .jpg lub .png\n",
        "image_files = [f for f in os.listdir(IMG_DIR) if f.lower().endswith(('.jpg', '.png'))]\n",
        "\n",
        "cropped_count = 0\n",
        "copied_count = 0\n",
        "\n",
        "print(f\"Start: {len(image_files)} zdjęć. Dodatkowe cięcie: {EXTRA_CROP*100}%\")\n",
        "\n",
        "# pętla po wszystkich zdjęciach z użyciem paska postępu\n",
        "for f in tqdm(image_files, desc=\"Przetwarzanie\"):\n",
        "\n",
        "    # tworzenie pełnych ścieżek\n",
        "    src_path = os.path.join(IMG_DIR, f)\n",
        "    dst_path = os.path.join(PROCESSED_DIR, f)\n",
        "\n",
        "    # wywołujemy cięcie\n",
        "    is_cropped, _ = crop_vignette(src_path, dst_path, threshold=VIGNETTE_THRESHOLD, extra_crop_percent=EXTRA_CROP, min_fill_ratio=MIN_FILL_RATIO)\n",
        "\n",
        "    if is_cropped:\n",
        "        # jeśli funkcja wykonała cięcie i zapisała plik -> zwiększ licznik\n",
        "        cropped_count += 1\n",
        "    else:\n",
        "        # jeśli funkcja nie przycięła zdjęcia (zwróciła False) -> kopiujemy oryginał bez zmian\n",
        "        shutil.copy(src_path, dst_path)\n",
        "        copied_count += 1\n",
        "\n",
        "print(\"\\nZakończono przycinanie.\")\n",
        "print(f\"Przycięto: {cropped_count}\")\n",
        "print(f\"Skopiowano (bez zmian): {copied_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmFpEzewsOsO"
      },
      "source": [
        "## Trening modelu DenseNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0b4STGjAp7L"
      },
      "source": [
        "### Wczytanie i modyfikacja modelu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btScV1GNuI9C"
      },
      "source": [
        "Wczytujemy model DenseNet-121, aby przyjrzeć się jego warstwie klasyfikacyjnej."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQZ7HHk_uFx-",
        "outputId": "c535c54e-8907-4230-920e-9d6ba6536da6"
      },
      "outputs": [],
      "source": [
        "# pobieramy model na chwilę, tylko do podglądu\n",
        "model = models.densenet121(weights='DEFAULT')\n",
        "print(model.classifier)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIUUABwUzb4F"
      },
      "source": [
        "Widzimy, że model na wyjściu ma 1000 klas, gdzie w naszym zbiorze jest tylko 8 klas. Należy zatem zmodyfikać warstwę klasyfikacjną."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqit4Va9z5-Q"
      },
      "source": [
        "Zbudujemy funkcję, która będzie wczytywać już wstępnie wytrenowany model oraz będzie modyfikować warstwę klasyfikacyjną."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ce1Sgc9zuFsg"
      },
      "outputs": [],
      "source": [
        "def get_model(device=DEVICE):\n",
        "    \"\"\"\n",
        "    Inicjalizuje architekturę DenseNet-121 i dostosowuje ją do zadania klasyfikacji zmian skórnych.\n",
        "\n",
        "    Funkcja realizuje strategięuczenia transferowego:\n",
        "    1. Pobiera wagi wstępnie wytrenowane na zbiorze ImageNet.\n",
        "    2. Wprowadza mechanizm regularyzacji wewnątrz bloków zagęszczonych (drop_rate).\n",
        "    3. Zastępuje oryginalny klasyfikator z dodatkowym Dropoutem,\n",
        "       dostosowaną do specyficznej liczby klas zbioru ISIC.\n",
        "\n",
        "    Args:\n",
        "        device (torch.device): Urządzenie obliczeniowe, na które zostanie przeniesiony model (CPU lub CUDA).\n",
        "\n",
        "    Returns:\n",
        "        torch.nn.Module: Skompilowany model PyTorch gotowy do treningu.\n",
        "    \"\"\"\n",
        "    # pobieramy model z wytrenowanymi wagami\n",
        "    # wprowadzamy wyłączanie neuronów w drop_rate\n",
        "    model = models.densenet121(weights='DEFAULT', drop_rate=0.2)\n",
        "\n",
        "    # pobieramy liczbę cech wchodzących do ostatniej warstwy (dla DenseNet121 to 1024)\n",
        "    in_features = model.classifier.in_features\n",
        "\n",
        "    # podmieniamy warstwę klasyfikacyjną (dodajemy Dropout)\n",
        "    model.classifier = nn.Sequential(\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(in_features, NUM_CLASSES)\n",
        "    )\n",
        "\n",
        "    # przenosimy model na GPU (jeśli dostępne)\n",
        "    model = model.to(device)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPphFo8CuFp0",
        "outputId": "2b44554c-adc5-4797-c974-d5b21a37be52"
      },
      "outputs": [],
      "source": [
        "model = get_model(DEVICE)\n",
        "print(model.classifier)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FLjjFUO1SYT"
      },
      "source": [
        "Zobaczymy również jego złożoność (liczbętrenowanych parametrów)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_t00BKguFm8",
        "outputId": "3e912509-c8cf-46ec-9ff8-c7629bc42c62"
      },
      "outputs": [],
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"Wszystkie parametry: {total_params:,}\")\n",
        "print(f\"Trenowalne parametry: {trainable_params:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8PdR9aEAtmJ"
      },
      "source": [
        "### Budowa pętli treningowej"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hKrsnHFAmTI"
      },
      "source": [
        "Możemy teraz rozpocząć budowanie pętli treningowej modelu. Trening będzie przebiegał następująco dla kazdego z podzbiorów.\n",
        "1. Konstruujemy zbiór treningowy i walidacyjny na podstawie metadanych i przy pomocy klasy `ISICDataset`\n",
        "2. Konstruujemy instancje klasy `DataLoader\n",
        "3. Inicjalizujemy wstępnie wytrenowany model DenseNet-121 i podmieniamy warstwę klasyfikacyjną.\n",
        "3. Definiujemy funkcję straty\n",
        "4. Przeprowadzamy pierwszy etap treningu:\n",
        "    1. Mrozimy wszystkie wagi modelu (poza warstwą klasyfikacyjną).\n",
        "    2. Trenujemy model przez małą liczbę epok wraz z mechanizmem wczesnego zatrzymania (w oparciu o wartość MCC).\n",
        "5. Przeprowadzamy drugi etap treningu:\n",
        "    1. Odmrażamy dwa ostatnie bloki gęste.\n",
        "    2. Trenujemy model przez dużą liczbę epok z mechanizmem wczensgeo zatrzymania (w oparciu o wartość MCC) oraz harmonogramowaniem współczynnika uczenia.\n",
        "6. Zapisujemy wyniki i wagi modelu.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcQmacS9A0Xk"
      },
      "source": [
        "Przywołujemy klasę `ISICDataset` oraz transformacje augumentacyjne."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkwFlgMJsTMD"
      },
      "outputs": [],
      "source": [
        "class ISICDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Niestandardowy Dataset PyTorch do wczytywania obrazów dermatologicznych ISIC.\n",
        "\n",
        "    Klasa wczytuje obrazy na podstawie ścieżek z DataFrame, konwertuje je do RGB\n",
        "    i zwraca w formie gotowej do przetworzenia przez model.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataframe, root_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Inicjalizuje dataset.\n",
        "\n",
        "        Args:\n",
        "            dataframe (pd.DataFrame): Ramka danych zawierająca co najmniej kolumny:\n",
        "                                      - 'nazwa_pliku': nazwa pliku z rozszerzeniem (np. 'IMG_1.jpg')\n",
        "                                      - 'target': numeryczna etykieta klasy (int).\n",
        "            root_dir (str): Ścieżka do katalogu głównego, w którym znajdują się obrazy.\n",
        "            transform (callable, optional): Opcjonalne transformacje (np. augmentacja, normalizacja)\n",
        "                                            aplikowane na obrazie. Domyślnie None.\n",
        "        \"\"\"\n",
        "        self.df = dataframe\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Zwraca całkowitą liczbę próbek w zbiorze.\"\"\"\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Pobiera pojedynczą próbkę danych o podanym indeksie.\n",
        "\n",
        "        Args:\n",
        "            idx (int/tensor): Indeks próbki do pobrania.\n",
        "\n",
        "        Returns:\n",
        "            tuple: Krotka (image, label), gdzie:\n",
        "                   - image (PIL.Image lub Tensor): Obraz po transformacjach.\n",
        "                   - label (int): Numeryczna etykieta klasy.\n",
        "        \"\"\"\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        # pobranie nazwy pliku\n",
        "        img_name = self.df.iloc[idx]['nazwa_pliku']\n",
        "        img_path = os.path.join(self.root_dir, img_name)\n",
        "\n",
        "        # wczytanie obrazu i konwersja na RGB (dla bezpieczeństwa)\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        # pobranie etykiety numerycznej (target)\n",
        "        label = self.df.iloc[idx]['target']\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1suSZ7fcse5t"
      },
      "outputs": [],
      "source": [
        "working_size = int(IMG_SIZE * 1.25)\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    # losujemy wycinek od 80% do 100% powierzchni oryginalnego obrazu\n",
        "    transforms.RandomResizedCrop(working_size, scale=(0.8, 1.0), ratio=(0.9, 1.1)),\n",
        "\n",
        "    # losowe odbicia lustrzane pionowo i poziomo\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "\n",
        "    # delikatna zmiana koloru\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1, hue=0.0),\n",
        "\n",
        "    # obrót zdjęcia o kąt z przedziału (-15 stopni, 15 stopni)\n",
        "    transforms.RandomRotation(15),\n",
        "\n",
        "    # wycinamy środek obrazu w docelowych wymiarach\n",
        "    transforms.CenterCrop(IMG_SIZE),\n",
        "\n",
        "    # przeniesienie na tensor i normalizacja\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(NORM_MEAN, NORM_STD)\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    # zmiana wymiarów\n",
        "    transforms.Resize(working_size),\n",
        "    # wycinamy środek obrazu w docelowych wymiarach\n",
        "    transforms.CenterCrop(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(NORM_MEAN, NORM_STD)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VB9q6HfwBMsz"
      },
      "source": [
        "Konstruujemy funkcją przeprowadzającą trening na jednej epoce."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5d8al7yABQlw"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, dataloader, criterion, optimizer, device, scaler=None):\n",
        "    \"\"\"\n",
        "    Realizuje jedną pełną epokę treningową modelu.\n",
        "\n",
        "    Funkcja iteruje przez wszystkie partie danych treningowych,\n",
        "    oblicza błędy predykcji, wyznacza gradienty i aktualizuje wagi modelu.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): Model sieci neuronowej do wytrenowania.\n",
        "        dataloader (DataLoader): Generator dostarczający dane treningowe w partiach.\n",
        "        criterion (nn.Module): Funkcja straty (np. CrossEntropyLoss).\n",
        "        optimizer (torch.optim.Optimizer): Algorytm optymalizujący wagi (np. AdamW).\n",
        "        device (torch.device): Urządzenie obliczeniowe (CPU/CUDA).\n",
        "\n",
        "    Returns:\n",
        "        float: Średnia wartość funkcji straty dla całej epoki.\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # pasek postępu\n",
        "    pbar = tqdm(dataloader, desc=\"  Trening\", leave=False)\n",
        "\n",
        "    for inputs, labels in pbar:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if scaler is not None:\n",
        "            # szybkie obliczenia\n",
        "            with torch.amp.autocast(device_type='cuda'):\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            # skalowanie gradientów i krok optymalizatora\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        pbar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    return epoch_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CmSUSyCBRbZ"
      },
      "source": [
        "Konstruujemy funkcję przeprowadzającą ewaluację. Dodatkowo konstruujemy funkcję do obliczenia specyficzności (nie znaleziono gotowej funkcji)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzV8F-YhIlh8"
      },
      "outputs": [],
      "source": [
        "def calculate_specificity(y_true, y_pred, num_classes):\n",
        "    \"\"\"\n",
        "    Oblicza średnią specyficzność dla klasyfikacji wieloklasowej.\n",
        "\n",
        "    Funkcja wykorzystuje strategię One-vs-Rest, obliczając specyficzność niezależnie\n",
        "    dla każdej klasy (binarna klasyfikacja: dana klasa vs reszta), a następnie zwraca\n",
        "    ich średnią arytmetyczną. Jest to kluczowa metryka w diagnostyce,\n",
        "    określająca zdolność modelu do poprawnego wykluczania danej choroby.\n",
        "\n",
        "    Args:\n",
        "        y_true (array-like): Wektor rzeczywistych etykiet.\n",
        "        y_pred (array-like): Wektor przewidzianych etykiet.\n",
        "        num_classes (int): Całkowita liczba klas w modelu.\n",
        "\n",
        "    Returns:\n",
        "        float: Uśredniona wartość specyficzności (zakres 0.0 - 1.0).\n",
        "    \"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=range(num_classes))\n",
        "    specificity_per_class = []\n",
        "\n",
        "    for i in range(num_classes):\n",
        "        # dla klasy 'i':\n",
        "        # TN = suma wszystkich próbek, które nie są 'i' i nie zostały przewidziane jako 'i'\n",
        "        # FP = próbki, które nie są 'i', ale zostały przewidziane jako 'i'\n",
        "\n",
        "        # wartości w macierzt pomyłek:\n",
        "        # cm[i, i] to TP\n",
        "        # cm[:, i] to kolumna predykcji (suma to TP + FP) -> FP = suma_kol - TP\n",
        "        # cm[i, :] to wiersz prawdy (suma to TP + FN)\n",
        "        # suma całkowita to total\n",
        "\n",
        "        tp = cm[i, i]\n",
        "        fp = cm[:, i].sum() - tp\n",
        "        fn = cm[i, :].sum() - tp\n",
        "        tn = cm.sum() - (tp + fp + fn)\n",
        "\n",
        "        # Specyficzność = TN / (TN + FP) z mechanizm uniknięcia dzielenia przez 0\n",
        "        if (tn + fp) > 0:\n",
        "            spec = tn / (tn + fp)\n",
        "        else:\n",
        "            spec = 0.0\n",
        "        specificity_per_class.append(spec)\n",
        "\n",
        "    return np.mean(specificity_per_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9CBvDdTBc6d"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader, criterion, device):\n",
        "    \"\"\"\n",
        "    Przeprowadza proces ewaluacji modelu na zbiorze walidacyjnym lub testowym.\n",
        "\n",
        "    Funkcja przełącza model w tryb inferencji (wyłącza obliczanie gradientów), co optymalizuje\n",
        "    zużycie pamięci i przyspiesza obliczenia. Następnie generuje predykcje dla całego zbioru\n",
        "    i oblicza zestaw metryk diagnostycznych. Zastosowanie uśredniania typu 'macro' pozwala\n",
        "    na rzetelną ocenę klas rzadkich (np. czerniaka) w niezbalansowanym zbiorze danych.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): Model sieci neuronowej poddawany ocenie.\n",
        "        dataloader (DataLoader): Generator dostarczający dane walidacyjne/testowe.\n",
        "        criterion (nn.Module): Funkcja straty używana do oceny błędu predykcji.\n",
        "        device (torch.device): Urządzenie obliczeniowe (CPU lub CUDA).\n",
        "\n",
        "    Returns:\n",
        "        dict: Słownik zawierający obliczone wartości metryk:\n",
        "            - 'strata': Średnia wartość funkcji straty.\n",
        "            - 'dokładność': Dokładność.\n",
        "            - 'mcc': Współczynnik korelacji Matthewsa.\n",
        "            - 'czułość': Czułość.\n",
        "            - 'precyzja': Precyzja.\n",
        "            - 'specyficzność': Specyficznosć.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "\n",
        "    # obliczamy mertyki\n",
        "    # average='macro' traktuje każdą klasę na równi\n",
        "    acc = accuracy_score(all_labels, all_preds) # dokładność\n",
        "    mcc = matthews_corrcoef(all_labels, all_preds) # współczynnik korelacji Mattewsa\n",
        "    sens = recall_score(all_labels, all_preds, average='macro', zero_division=0) # czułość\n",
        "    prec = precision_score(all_labels, all_preds, average='macro', zero_division=0) # precyzja\n",
        "    spec = calculate_specificity(all_labels, all_preds, NUM_CLASSES) # specyficzność\n",
        "\n",
        "    return {\n",
        "        'strata': epoch_loss,\n",
        "        'dokładność': acc,\n",
        "        'mcc': mcc,\n",
        "        'czułość': sens,\n",
        "        'precyzja': prec,\n",
        "        'specyficzność': spec\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LH8Yr6ooBfXh"
      },
      "source": [
        "Konstruujemy funkcją inicjalizującą funkcję straty. Funkcja oblicza wagi poszczególnych klas, aby móc balansować nierówne ich rózłożenie w zbiorze. Dodatkowo zacieramy delikatnie granice między klasami ze względu na to, że wiele zmian złośliwych i łagodnych jest do siebie zbliżonych wizualnie."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJT8q_ZTBoBW"
      },
      "outputs": [],
      "source": [
        "def get_loss(train_df, device):\n",
        "    \"\"\"\n",
        "    Konfiguruje funkcję straty (Loss Function) z mechanizmem równoważenia klas.\n",
        "\n",
        "    Funkcja oblicza wagi dla każdej klasy na podstawie ich liczebności w zbiorze treningowym,\n",
        "    stosując strategię \"odwrotności pierwiastka\" (1/sqrt(N)). Jest to podejście łagodniejsze\n",
        "    niż prosta odwrotność częstości, zapobiegające niestabilności gradientów w przypadku\n",
        "    bardzo rzadkich klas. Dodatkowo wagi są normalizowane do średniej 1.0, a funkcja straty\n",
        "    wykorzystuje Label Smoothing (0.1) w celu zapobiegania nadmiernej pewności modelu.\n",
        "\n",
        "    Args:\n",
        "        train_df (pd.DataFrame): Ramka danych zbioru treningowego (wymagana kolumna 'target').\n",
        "        device (torch.device): Urządzenie obliczeniowe (CPU/CUDA), na którym umieszczone zostaną wagi.\n",
        "\n",
        "    Returns:\n",
        "        nn.CrossEntropyLoss: Instancja funkcji straty z załadowanymi wagami i wygładzaniem etykiet.\n",
        "    \"\"\"\n",
        "    # zliczamy wystąpienia klas\n",
        "    class_counts = train_df['target'].value_counts().sort_index().values\n",
        "\n",
        "    # obliczamy wagi\n",
        "    weights = 1. / np.sqrt(class_counts)\n",
        "\n",
        "    # normalizujemy wagi\n",
        "    weights = weights / np.mean(weights)\n",
        "\n",
        "    # zmieniamy na tensor i przeniesienie na GPU/CPU\n",
        "    weights_tensor = torch.FloatTensor(weights).to(device)\n",
        "\n",
        "    # zwracamy gotową funkcję\n",
        "    return nn.CrossEntropyLoss(weight=weights_tensor, label_smoothing=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYr1o_2IB5nq"
      },
      "source": [
        "Konstruujemy funkcję, która będzie zamrażać lub odmarażać wagi modeli. Do tego będzie zwracać odpwiedni optymalizator i ewentualnie obiekt do harmonogramowania współczynnika uczenia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtGAxEI_CHgb"
      },
      "outputs": [],
      "source": [
        "def setup_stage(model, stage):\n",
        "    \"\"\"\n",
        "    Konfiguruje hiperparametry treningu oraz stan zamrożenia warstw dla danego etapu.\n",
        "\n",
        "    Funkcja realizuje strategię dwuetapowego uczenia transferowego:\n",
        "    1. 'trening klasyfikatora': Zamraża cały ekstraktor cech, aktualizując wagi jedynie\n",
        "       w nowej głowicy klasyfikacyjnej.\n",
        "    2. 'dostrajanie modelu': Odmraża kluczowe bloki konwolucyjne (DenseBlock 3 i 4),\n",
        "       zmniejsza learning rate i aktywuje scheduler w celu precyzyjnego dopasowania wag.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): Model DenseNet-121.\n",
        "        stage (str): Identyfikator etapu ('trening klasyfikatora' lub 'dostrajanie modelu').\n",
        "\n",
        "    Returns:\n",
        "        tuple: Krotka konfiguracyjna (optimizer, scheduler, num_epochs, patience).\n",
        "    \"\"\"\n",
        "    if stage == 'trening klasyfikatora':\n",
        "        print(\"\\nKonfiguracja etapu 1: Trening klasyfikatora\")\n",
        "        for param in model.features.parameters(): param.requires_grad = False\n",
        "        for param in model.classifier.parameters(): param.requires_grad = True\n",
        "\n",
        "        optimizer = optim.AdamW(model.classifier.parameters(), lr=WARMUP_LR, weight_decay=WEIGHT_DECAY)\n",
        "        scheduler = None # w pierwszym etapie scheduler jest zbędny\n",
        "\n",
        "        return optimizer, scheduler, WARMUP_EPOCHS, WARMUP_PATIENCE\n",
        "\n",
        "    elif stage == 'dostrajanie modelu':\n",
        "        print(\"\\nKonfiguracja etapu 2: Dostrajanie modelu\")\n",
        "        # odmrażamy ostatni blok\n",
        "        for param in model.features.denseblock4.parameters(): param.requires_grad = True\n",
        "        for param in model.features.norm5.parameters(): param.requires_grad = True\n",
        "\n",
        "        # odmrażamy kolejny blok\n",
        "        for param in model.features.transition3.parameters(): param.requires_grad = True\n",
        "        for param in model.features.denseblock3.parameters(): param.requires_grad = True\n",
        "\n",
        "        optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()),\n",
        "                                lr=FINETUNE_LR, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "        # definiujemy harmonogramowane learning_rate w oparciu o poprawę MCC\n",
        "        scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n",
        "\n",
        "        return optimizer, scheduler, FINETUNE_EPOCHS, FINETUNE_PATIENCE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_02p6uWSCnUu"
      },
      "source": [
        "Konstruujemy funkcję do obsługi instancji klas `ISICDataset`, `DataLoader` oraz do dzielenia zbioru na podstawie metadanych"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jEwidcICzWu"
      },
      "outputs": [],
      "source": [
        "def get_fold_data(df, fold_idx):\n",
        "    \"\"\"\n",
        "    Inicjalizuje generatory danych (DataLoaders) dla określonego foldu walidacji krzyżowej.\n",
        "\n",
        "    Funkcja dzieli zbiór danych na podzbiór treningowy (wszystkie foldy poza obecnym)\n",
        "    i walidacyjny (obecny fold). Następnie tworzy instancje klasy Dataset z odpowiednimi\n",
        "    transformacjami oraz konfiguruje DataLoadery z obsługą wielowątkowości i transferu\n",
        "    pamięci do GPU (pin_memory).\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): Główna ramka danych zawierająca metadane i przypisane numery foldów.\n",
        "        fold_idx (int): Indeks aktualnego foldu, który ma służyć jako zbiór walidacyjny.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (train_loader, val_loader, train_df) - Krotka zawierająca gotowe loadery\n",
        "               oraz ramkę danych treningowych (potrzebną np. do wyliczenia wag klas).\n",
        "    \"\"\"\n",
        "    # filtrujemy zbiór treningowy\n",
        "    train_df = df[(df['typ_puli'] == 'trening') & (df['nr_podzbioru'] != fold_idx)].reset_index(drop=True)\n",
        "\n",
        "    # filtrujemy zbiór walidacyjny\n",
        "    val_df = df[(df['typ_puli'] == 'trening') & (df['nr_podzbioru'] == fold_idx)].reset_index(drop=True)\n",
        "\n",
        "    # inicjalizujemy instancje klasy\n",
        "    train_ds = ISICDataset(train_df, PROCESSED_DIR, transform=train_transforms)\n",
        "    val_ds = ISICDataset(val_df, PROCESSED_DIR, transform=val_transforms)\n",
        "\n",
        "    # konfigurujemy loadery\n",
        "    # drop_last=True usuwa ostatnią niepełną partię danych\n",
        "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                              num_workers=NUM_WORKERS, pin_memory=True,\n",
        "                              drop_last=True)\n",
        "\n",
        "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
        "                            num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "    return train_loader, val_loader, train_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OY81Vg8LYgge"
      },
      "source": [
        "Konstruujemy również funkcję do zbierania predykcji na zbiorze walidacyjnym."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWVJ9wBAYlGS"
      },
      "outputs": [],
      "source": [
        "def get_predictions(model, loader, device):\n",
        "    \"\"\"\n",
        "    Generuje predykcje dla całego dataloader'a (używane na koniec foldu).\n",
        "    Zwraca: y_true (list), y_pred (list)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            # pobieramy klasę o najwyższym prawdopodobieństwie\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy().tolist())\n",
        "            all_labels.extend(labels.cpu().numpy().tolist())\n",
        "\n",
        "    return all_labels, all_preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zzcti9fLC6nm"
      },
      "source": [
        "Na koniec konstruujemy funkcję, która przeprowadza trening na pojedynczym foldzie. Trening odbywa się w dwóch etapach:\n",
        "1. Trenujemy zamrożony model, czyli trenujemy wyłącznie warstwę klasyfikacyjną. Ma to na celu uniknięcie tzw. szkoku gradientowego, czyli drastycznej zmiany gradientów na początku fazy treningowej. Szok gradientowy zaburzyłby nam wagi już wytrenowanego modelu i wydłużyłby czas trwania treningu.\n",
        "2. Trenujemy model z odmrożonymi dwoma ostatnimi blokami. Pozowli dostroić warstwy konwolucyjne do wykrywania cech związanych ze zmianami skórnymi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riwD3p65Dotv"
      },
      "outputs": [],
      "source": [
        "def run_fold(fold_idx, df):\n",
        "    \"\"\"\n",
        "    Przeprowadza pełny cykl treningowy i walidacyjny dla pojedynczego foldu.\n",
        "\n",
        "    Funkcja zarządza całym procesem uczenia dla danego podziału danych:\n",
        "    1. Przygotowuje DataLoadery (trening/walidacja) dla wskazanego foldu.\n",
        "    2. Inicjalizuje model (transfer learning) i funkcję straty.\n",
        "    3. Realizuje dwuetapowy trening:\n",
        "        - Etap 1: Trening tylko głowicy klasyfikującej.\n",
        "        - Etap 2: Dostrajanie kluczowych warstw modelu.\n",
        "    4. Monitoruje metrykę MCC w celu zapisu najlepszego modelu .\n",
        "       Zapewnia bezpieczny zapis na dysk (wymuszenie synchronizacji os.fsync).\n",
        "    5. Stosuje mechanizm wczesnego zatrzymania  w przypadku braku poprawy.\n",
        "    6. Po zakończeniu treningu generuje predykcje walidacyjne, wczytując wagi\n",
        "       najlepszego modelu (a nie ostatniego stanu z pamięci).\n",
        "\n",
        "    Args:\n",
        "        fold_idx (int): Indeks bieżącego foldu (0..CV_FOLDS-1).\n",
        "        df (pd.DataFrame): Główna ramka danych z metadanymi (ścieżki, etykiety, split).\n",
        "\n",
        "    Returns:\n",
        "        tuple: Krotka (history, fold_predictions) zawierająca:\n",
        "            - history (dict): Słownik ze szczegółowym przebiegiem treningu (wartości straty,\n",
        "              metryki dla każdej epoki, czasy wykonania, najlepszy wynik MCC).\n",
        "            - fold_predictions (dict): Słownik z kluczami 'fold', 'y_true', 'y_pred',\n",
        "              zawierający ostateczne predykcje najlepszego modelu na zbiorze walidacyjnym.\n",
        "    \"\"\"\n",
        "    fold_start_time = time.time()\n",
        "    print(f\"\\n{'='*5}START TRENINGU FOLD {fold_idx}/{CV_FOLDS-1}{'='*5}\")\n",
        "\n",
        "    train_loader, val_loader, train_df = get_fold_data(df, fold_idx)\n",
        "    model = get_model(DEVICE)\n",
        "    criterion = get_loss(train_df, DEVICE)\n",
        "    scaler = torch.amp.GradScaler('cuda')\n",
        "\n",
        "    history = {'fold': fold_idx, 'metryki': []}\n",
        "    best_mcc_overall = -1.0 # najlepszy MCC w tym foldzie (z obu etapów)\n",
        "\n",
        "    # ścieżka docelowa (na Google Drive)\n",
        "    drive_model_path = os.path.join(MODELS_DIR, f'{MODEL_NAME}_fold{fold_idx}.pth')\n",
        "\n",
        "    # ścieżka tymczasowa (na szybkim dysku lokalnym Colaba)\n",
        "    local_model_path = f'/content/{MODEL_NAME}_fold{fold_idx}.pth'\n",
        "\n",
        "    # pętla po etapach\n",
        "    for stage_name in ['trening klasyfikatora', 'dostrajanie modelu']:\n",
        "        optimizer, scheduler, n_epochs, patience_limit = setup_stage(model, stage_name)\n",
        "\n",
        "        # reset liczników dla etapu\n",
        "        patience_cnt = 0\n",
        "        best_mcc_stage = -1.0\n",
        "\n",
        "        print(f\"Etap - {stage_name}: Liczba epok={n_epochs}, Cierpliwość={patience_limit}\")\n",
        "\n",
        "        for epoch in range(n_epochs):\n",
        "            # trening\n",
        "            t_loss = train_one_epoch(model, train_loader, criterion, optimizer, DEVICE, scaler)\n",
        "\n",
        "            # walidacja\n",
        "            metrics = evaluate(model, val_loader, criterion,DEVICE)\n",
        "\n",
        "            # wyniki\n",
        "            print(f\"\\tEpoka {epoch+1} | \"\n",
        "                    f\"Strata: {t_loss:.4f} | \"\n",
        "                    f\"Val MCC: {metrics['mcc']:.4f} | \"\n",
        "                    f\"Val Czułość: {metrics['czułość']:.4f} | \"\n",
        "                    f\"Val Specyficzność: {metrics['specyficzność']:.4f} | \"\n",
        "                    f\"Val Precyzja: {metrics['precyzja']:.4f} | \"\n",
        "                    f\"Val Dokładność: {metrics['dokładność']:.4f}\")\n",
        "\n",
        "            # zapis do historii\n",
        "            record = {\n",
        "                'etap': stage_name,\n",
        "                'ostatnia_epoka': epoch+1,\n",
        "                'strata_treningowa': t_loss,\n",
        "                **metrics # rozpakowanie słownika z metrykami\n",
        "            }\n",
        "            history['metryki'].append(record)\n",
        "\n",
        "            # harmonogramowanie współczynnika uczenia\n",
        "            if scheduler:\n",
        "                scheduler.step(metrics['mcc'])\n",
        "\n",
        "            # MECHANIZM WCZESNEGO ZATRZYMANIA\n",
        "            # sprawdzamy, czy to najlepszy model w ogóle w tym foldzie\n",
        "            # jeśli tak to zapisujemy jego wagi\n",
        "            if metrics['mcc'] > best_mcc_overall:\n",
        "                best_mcc_overall = metrics['mcc']\n",
        "\n",
        "                # zapisujemy na szybki dysk lokalny\n",
        "                torch.save(model.state_dict(), local_model_path)\n",
        "\n",
        "                # próbujemy skopiować na Drive\n",
        "                try:\n",
        "                    shutil.copy(local_model_path, drive_model_path)\n",
        "                    print(f\"\\t>>> Poprawa modelu! MCC: {best_mcc_overall:.4f}. Zapisano na Drive.\")\n",
        "                except Exception as e:\n",
        "                    print(f\"\\t>>> Poprawa modelu! Zapisano LOKALNIE. Błąd kopiowania na Drive: {e}\")\n",
        "\n",
        "            # logika wczesnego zatrzymania na poziomie etapu\n",
        "            if metrics['mcc'] > best_mcc_stage:\n",
        "                best_mcc_stage = metrics['mcc']\n",
        "                patience_cnt = 0\n",
        "            else:\n",
        "                patience_cnt += 1\n",
        "                if patience_cnt >= patience_limit:\n",
        "                    print(f\"  [Info] Zatrzymano trening w etapie {stage_name} po {epoch+1} epokach.\")\n",
        "                    break\n",
        "\n",
        "    fold_duration = time.time() - fold_start_time\n",
        "    history['czas_trwania_foldu'] = fold_duration\n",
        "    history['najlepsze_mcc'] = best_mcc_overall\n",
        "\n",
        "    # mechanizm generowanie predykcji na zbiorze walidacyjnym\n",
        "    print(f\"\\nGenerowanie predykcji dla foldu {fold_idx}...\")\n",
        "\n",
        "    # wczytujemy najlepszy model\n",
        "    if os.path.exists(local_model_path):\n",
        "        model.load_state_dict(torch.load(local_model_path))\n",
        "        print(\"Wczytano najlepszy model (kopia lokalna).\")\n",
        "    elif os.path.exists(drive_model_path):\n",
        "        model.load_state_dict(torch.load(drive_model_path))\n",
        "        print(\"Wczytano najlepszy model (z Google Drive).\")\n",
        "    else:\n",
        "        print(\"[Ostrzeżenie] Nie znaleziono zapisanego modelu, używam ostatniego stanu.\")\n",
        "\n",
        "    # generujemy predykcje\n",
        "    final_y_true, final_y_pred = get_predictions(model, val_loader, DEVICE)\n",
        "\n",
        "    # tworzymy osobny obiekt na predykcje\n",
        "    fold_predictions = {\n",
        "        'fold': fold_idx,\n",
        "        'y_true': final_y_true,\n",
        "        'y_pred': final_y_pred\n",
        "    }\n",
        "\n",
        "    print(f\"Koniec trening na foldzie {fold_idx}. Czas: {fold_duration/60:.1f} min. Najlepszy MCC: {best_mcc_overall:.4f}\")\n",
        "\n",
        "    # czyścimy pamięć\n",
        "    del model, optimizer, scheduler, train_loader, val_loader\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return history, fold_predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcb9HV-1Awrj"
      },
      "source": [
        "### Trening modelu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPpw0h1NDqy2"
      },
      "source": [
        "Mamy już przygotowany wszelkie potrzebne funkcje możemy przeprowadzić trening modelu DenseNet-121 na zbiorze ISIC2019. Zapisujemy wyniki treningu. Wprowadzamy również zabezpieczenia w razie przerwania sesji, aby oszczędzać jednostki obliczeniowe na GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ouyycyHJMfP",
        "outputId": "41ed85cb-fb3e-4799-ce0c-5226263ca24e"
      },
      "outputs": [],
      "source": [
        "cv_results = []\n",
        "densenet_preds = {'y_true': [], 'y_pred': []}\n",
        "global_start_time = time.time()\n",
        "\n",
        "print(f\"Trening na {CV_FOLDS} foldach.\")\n",
        "\n",
        "for fold_idx in range(CV_FOLDS):\n",
        "    # definiujemy ścieżki do plików, które mają powstać\n",
        "    results_path = os.path.join(RESULTS_DIR, f'{MODEL_NAME}_wyniki_treningu_fold_{fold_idx}.json')\n",
        "    preds_path = os.path.join(RESULTS_DIR, f'{MODEL_NAME}_predykcje_fold_{fold_idx}.json')\n",
        "    model_path = os.path.join(MODELS_DIR, f'{MODEL_NAME}_fold{fold_idx}.pth')\n",
        "\n",
        "    # MECHANIZM WZNAWIANIA\n",
        "    # sprawdzamy, czy ten fold został już w pełni policzony\n",
        "    if os.path.exists(results_path) and os.path.exists(preds_path) and os.path.exists(model_path):\n",
        "        print(f\"\\n[INFO] Fold {fold_idx} został już ukończony. Wczytuję wyniki z dysku i pomijam trening.\")\n",
        "\n",
        "        # wczytujemy historię treningu\n",
        "        with open(results_path, 'r') as f:\n",
        "            fold_hist = json.load(f)\n",
        "            cv_results.append(fold_hist)\n",
        "\n",
        "        # wczytujemy predykcje i doklejamy do listy zbiorczej\n",
        "        with open(preds_path, 'r') as f:\n",
        "            fold_preds = json.load(f)\n",
        "            densenet_preds['y_true'].extend(fold_preds['y_true'])\n",
        "            densenet_preds['y_pred'].extend(fold_preds['y_pred'])\n",
        "\n",
        "        continue # przechodzimy do następnego foldu\n",
        "\n",
        "    # jeśli plików nie ma, uruchamiamy trening normalnie\n",
        "    print(f\"\\n[INFO] Brak pełnych wyników dla Foldu {fold_idx}. Uruchamiam trening.\")\n",
        "\n",
        "    try:\n",
        "        # trenujemy model i zbieramy predykcje\n",
        "        fold_hist, fold_preds = run_fold(fold_idx, df)\n",
        "\n",
        "        # dodajemy metryki do listy wyników\n",
        "        cv_results.append(fold_hist)\n",
        "\n",
        "        # dodajemy predykcje do listy zbiorczej\n",
        "        densenet_preds['y_true'].extend(fold_preds['y_true'])\n",
        "        densenet_preds['y_pred'].extend(fold_preds['y_pred'])\n",
        "\n",
        "        # zapisujemy wyniki modelu\n",
        "        with open(results_path, 'w') as f:\n",
        "            json.dump(fold_hist, f)\n",
        "\n",
        "        # zapisujemy predykcje\n",
        "        with open(preds_path, 'w') as f:\n",
        "            json.dump(fold_preds, f)\n",
        "\n",
        "        print(f\"[SUKCES] Fold {fold_idx} zapisany bezpiecznie na Dysku.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n[BŁĄD KRYTYCZNY] Wystąpił błąd podczas foldu {fold_idx}: {e}\")\n",
        "        print(\"Zatrzymuję pętlę, abyś mógł naprawić błąd. Poprzednie foldy są bezpieczne.\")\n",
        "        break # przerywamy pętlę, żeby nie nadpisać czegoś błędami\n",
        "\n",
        "global_duration = time.time() - global_start_time\n",
        "print(f\"\\n{'='*5} Zakończono cały proces. Czas: {global_duration/60:.2f} min {'='*5}\")\n",
        "\n",
        "# zapisujemy zbiorczy plik z wynikami\n",
        "with open(os.path.join(RESULTS_DIR, f'{MODEL_NAME}_wyniki_FULL.json'), 'w') as f:\n",
        "    json.dump(cv_results, f)\n",
        "\n",
        "# zapisujemy zbiorczy plik z predykcjami\n",
        "with open(os.path.join(RESULTS_DIR, f'{MODEL_NAME}_cv_predictions_FULL.json'), 'w') as f:\n",
        "    json.dump(densenet_preds, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYxK0nlTdTPt"
      },
      "source": [
        "### Wizualizacja wyników treningu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixwvftS8TkMd"
      },
      "source": [
        "Spróbujemy zwizualizować wyniki treningu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHdyo9HeTm6g"
      },
      "outputs": [],
      "source": [
        "def plot_training_history(cv_results, save_dir=None, filename=\"analiza_treningu.png\"):\n",
        "    \"\"\"\n",
        "    Generuje kompleksową wizualizację przebiegu treningu w układzie siatki 2x3.\n",
        "\n",
        "    Funkcja tworzy wykresy typu 'spaghetti', prezentując stabilność modelu poprzez\n",
        "    nałożenie wyników poszczególnych foldów (cienkie linie) na średni trend (gruba linia).\n",
        "    Wizualizuje kluczowe metryki diagnostyczne oraz automatycznie oznacza moment\n",
        "    rozpoczęcia etapu dostrajania czerwoną linią przerywaną.\n",
        "\n",
        "    Args:\n",
        "        cv_results (list): Lista słowników z historią treningu dla każdego foldu.\n",
        "        save_dir (str, optional): Ścieżka do katalogu zapisu wykresu.\n",
        "        filename (str, optional): Nazwa pliku wynikowego.\n",
        "    \"\"\"\n",
        "\n",
        "    # KROK 1: przygotowanie danych\n",
        "    plot_data = []\n",
        "    fine_tune_start_epochs = []\n",
        "\n",
        "    for fold_res in cv_results:\n",
        "        fold_idx = fold_res['fold']\n",
        "        metrics = fold_res['metryki']\n",
        "\n",
        "        global_epoch = 0\n",
        "        ft_start_found = False\n",
        "\n",
        "        for record in metrics:\n",
        "            global_epoch += 1\n",
        "            stage = record.get('etap', 'nieznany')\n",
        "\n",
        "            # wykrycie momentu dostrajania\n",
        "            if stage == 'dostrajanie modelu' and not ft_start_found:\n",
        "                fine_tune_start_epochs.append(global_epoch)\n",
        "                ft_start_found = True\n",
        "\n",
        "            # dodajemy dane do listy\n",
        "            # strata\n",
        "            plot_data.append({'Fold': fold_idx, 'Epoka': global_epoch, 'Wartość': record.get('strata_treningowa', 0), 'Metryka': 'Strata treningowa'})\n",
        "            plot_data.append({'Fold': fold_idx, 'Epoka': global_epoch, 'Wartość': record.get('strata', 0), 'Metryka': 'Strata walidacyjna'})\n",
        "\n",
        "            # metryki\n",
        "            plot_data.append({'Fold': fold_idx, 'Epoka': global_epoch, 'Wartość': record.get('mcc', 0), 'Metryka': 'MCC'})\n",
        "            plot_data.append({'Fold': fold_idx, 'Epoka': global_epoch, 'Wartość': record.get('dokładność', 0), 'Metryka': 'Dokładność'})\n",
        "            plot_data.append({'Fold': fold_idx, 'Epoka': global_epoch, 'Wartość': record.get('czułość', 0), 'Metryka': 'Czułość'})\n",
        "            plot_data.append({'Fold': fold_idx, 'Epoka': global_epoch, 'Wartość': record.get('specyficzność', 0), 'Metryka': 'Specyficzność'})\n",
        "            plot_data.append({'Fold': fold_idx, 'Epoka': global_epoch, 'Wartość': record.get('precyzja', 0), 'Metryka': 'Precyzja'})\n",
        "\n",
        "    df = pd.DataFrame(plot_data)\n",
        "    avg_ft_start = np.mean(fine_tune_start_epochs) if fine_tune_start_epochs else None\n",
        "\n",
        "    # KROK 2: rysowanie\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(24, 12))\n",
        "    fig.suptitle(f'Analiza treningu ({len(cv_results)} Foldów)', fontsize=20, y=0.95)\n",
        "\n",
        "    # spłaszczamy tablicę osi\n",
        "    axes_flat = axes.flatten()\n",
        "\n",
        "    # definiujemy co i gdzie rysować\n",
        "    # format: (Tytuł, lista metryk do pokazania, zakres osi Y)\n",
        "    charts_config = [\n",
        "        ('Funkcja straty', ['Strata treningowa', 'Strata walidacyjna'], None),\n",
        "        ('Współczynnik korelacji Mathewsa', ['MCC'], (0.0, 1.0)),\n",
        "        ('Dokładność', ['Dokładność'], (0.0, 1.0)),\n",
        "        ('Czułość', ['Czułość'], (0.0, 1.0)),\n",
        "        ('Specyficzność', ['Specyficzność'], (0.0, 1.0)),\n",
        "        ('Precyzja', ['Precyzja'], (0.0, 1.0))\n",
        "    ]\n",
        "\n",
        "    for i, (title, metrics_to_plot, ylim) in enumerate(charts_config):\n",
        "        ax = axes_flat[i]\n",
        "\n",
        "        # filtrujemy dane dla danego wykresu\n",
        "        subset = df[df['Metryka'].isin(metrics_to_plot)]\n",
        "\n",
        "        # wykres spaghetti - cienkie linie dla każdego foldu\n",
        "        sns.lineplot(data=subset, x='Epoka', y='Wartość', hue='Metryka', units='Fold',\n",
        "                     estimator=None, lw=0.6, alpha=0.3, ax=ax, legend=False, palette='tab10')\n",
        "\n",
        "        # średnia - gruba linia\n",
        "        sns.lineplot(data=subset, x='Epoka', y='Wartość', hue='Metryka',\n",
        "                     lw=3, errorbar=None, ax=ax, palette='tab10')\n",
        "\n",
        "        # linia startu dostrajania\n",
        "        if avg_ft_start:\n",
        "            ax.axvline(avg_ft_start, color='red', linestyle='--', alpha=0.5)\n",
        "            # podpis tylko na pierwszym wykresie\n",
        "            if i == 0:\n",
        "                ax.text(avg_ft_start + 0.2, ax.get_ylim()[1]*0.95, 'Fine-tune', color='red', rotation=90)\n",
        "\n",
        "        # aspekty kosmetyczne\n",
        "        ax.set_title(title, fontsize=14, fontweight='bold')\n",
        "        ax.set_xlabel('Epoka')\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        if ylim: ax.set_ylim(ylim)\n",
        "\n",
        "        # legenda\n",
        "        handles, labels = ax.get_legend_handles_labels()\n",
        "        if handles:\n",
        "            by_label = dict(zip(labels, handles))\n",
        "            ax.legend(by_label.values(), by_label.keys(), loc='lower right')\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Zostaw miejsce na tytuł główny\n",
        "\n",
        "    if save_dir:\n",
        "        save_path = os.path.join(save_dir, filename)\n",
        "        plt.savefig(save_path)\n",
        "        print(f\"Wykresy zapisano w: {save_path}\")\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0SxwbUpTqLR",
        "outputId": "bd639ac7-6e31-49f3-eafc-a15d7c650d46"
      },
      "outputs": [],
      "source": [
        "plot_training_history(cv_results, save_dir=RESULTS_DIR, filename=\"analiza_treningu_densenet.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nM9c7XXGMnPP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
